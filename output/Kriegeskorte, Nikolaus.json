[{"PMID": "38661128", "Title": "Emergence of brain-like mirror-symmetric viewpoint tuning in convolutional neural networks.", "Abstract": "Primates can recognize objects despite 3D geometric variations such as in-depth rotations. The computational mechanisms that give rise to such invariances are yet to be fully understood. A curious case of partial invariance occurs in the macaque face-patch AL and in fully connected layers of deep convolutional networks in which neurons respond similarly to mirror-symmetric views (e.g. left and right profiles). Why does this tuning develop? Here, we propose a simple learning-driven explanation for mirror-symmetric viewpoint tuning. We show that mirror-symmetric viewpoint tuning for faces emerges in the fully connected layers of convolutional deep neural networks trained on object recognition tasks, even when the training dataset does not include faces. First, using 3D objects rendered from multiple views as test stimuli, we demonstrate that mirror-symmetric viewpoint tuning in convolutional neural network models is not unique to faces: it emerges for multiple object categories with bilateral symmetry. Second, we show why this invariance emerges in the models. Learning to discriminate among bilaterally symmetric object categories induces reflection-equivariant intermediate representations. AL-like mirror-symmetric tuning is achieved when such equivariant responses are spatially pooled by downstream units with sufficiently large receptive fields. These results explain how mirror-symmetric viewpoint tuning can emerge in neural networks, providing a theory of how they might emerge in the primate brain. Our theory predicts that mirror-symmetric viewpoint tuning can emerge as a consequence of exposure to bilaterally symmetric objects beyond the category of faces, and that it can generalize beyond previously experienced object categories.", "Keywords": ["face processing", "neural networks", "neuroscience", "none", "primate vision", "symmetry"], "MeSH terms": ["Animals", "Neural Networks, Computer", "Brain", "Neurons", "Macaca", "Models, Neurological", "Macaca mulatta"], "Authors": [{"First Name": "Amirhossein", "Last Name": "Farzmahdi", "Affiliation": "Laboratory of Neural Systems, The Rockefeller University, New York, United States."}, {"First Name": "Wilbert", "Last Name": "Zarco", "Affiliation": "Laboratory of Neural Systems, The Rockefeller University, New York, United States."}, {"First Name": "Winrich A", "Last Name": "Freiwald", "Affiliation": "Laboratory of Neural Systems, The Rockefeller University, New York, United States."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Zuckerman Mind Brain Behavior Institute, Columbia University, New York, United States."}, {"First Name": "Tal", "Last Name": "Golan", "Affiliation": "Zuckerman Mind Brain Behavior Institute, Columbia University, New York, United States."}], "Journal": "eLife", "PubDate": "2024Apr25"}, {"PMID": "38512838", "Title": "Can neural networks benefit from objectives that encourage iterative convergent computations? A case study of ResNets and object classification.", "Abstract": "Recent work has suggested that feedforward residual neural networks (ResNets) approximate iterative recurrent computations. Iterative computations are useful in many domains, so they might provide good solutions for neural networks to learn. However, principled methods for measuring and manipulating iterative convergence in neural networks remain lacking. Here we address this gap by 1) quantifying the degree to which ResNets learn iterative solutions and 2) introducing a regularization approach that encourages the learning of iterative solutions. Iterative methods are characterized by two properties: iteration and convergence. To quantify these properties, we define three indices of iterative convergence. Consistent with previous work, we show that, even though ResNets can express iterative solutions, they do not learn them when trained conventionally on computer-vision tasks. We then introduce regularizations to encourage iterative convergent computation and test whether this provides a useful inductive bias. To make the networks more iterative, we manipulate the degree of weight sharing across layers using soft gradient coupling. This new method provides a form of recurrence regularization and can interpolate smoothly between an ordinary ResNet and a \"recurrent\" ResNet (i.e., one that uses identical weights across layers and thus could be physically implemented with a recurrent network computing the successive stages iteratively across time). To make the networks more convergent we impose a Lipschitz constraint on the residual functions using spectral normalization. The three indices of iterative convergence reveal that the gradient coupling and the Lipschitz constraint succeed at making the networks iterative and convergent, respectively. To showcase the practicality of our approach, we study how iterative convergence impacts generalization on standard visual recognition tasks (MNIST, CIFAR-10, CIFAR-100) or challenging recognition tasks with partial occlusions (Digitclutter). We find that iterative convergent computation, in these tasks, does not provide a useful inductive bias for ResNets. Importantly, our approach may be useful for investigating other network architectures and tasks as well and we hope that our study provides a useful starting point for investigating the broader question of whether iterative convergence can help neural networks in their generalization.", "Keywords": [], "MeSH terms": ["Neural Networks, Computer", "Learning", "Generalization, Psychological"], "Authors": [{"First Name": "Samuel", "Last Name": "Lippl", "Affiliation": "Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY, United States of America."}, {"First Name": "Benjamin", "Last Name": "Peters", "Affiliation": "Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY, United States of America."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY, United States of America."}], "Journal": "PloS one", "PubDate": "2024"}, {"PMID": "38259351", "Title": "How does the primate brain combine generative and discriminative computations in vision?", "Abstract": "Vision is widely understood as an inference problem. However, two contrasting conceptions of the inference process have each been influential in research on biological vision as well as the engineering of machine vision. The first emphasizes bottom-up signal flow, describing vision as a largely feedforward, discriminative inference process that filters and transforms the visual information to remove irrelevant variation and represent behaviorally relevant information in a format suitable for downstream functions of cognition and behavioral control. In this conception, vision is driven by the sensory data, and perception is direct because the processing proceeds from the data to the latent variables of interest. The notion of \"inference\" in this conception is that of the engineering literature on neural networks, where feedforward convolutional neural networks processing images are said to perform inference. The alternative conception is that of vision as an inference process in Helmholtz's sense, where the sensory evidence is evaluated in the context of a generative model of the causal processes that give rise to it. In this conception, vision inverts a generative model through an interrogation of the sensory evidence in a process often thought to involve top-down predictions of sensory data to evaluate the likelihood of alternative hypotheses. The authors include scientists rooted in roughly equal numbers in each of the conceptions and motivated to overcome what might be a false dichotomy between them and engage the other perspective in the realm of theory and experiment. The primate brain employs an unknown algorithm that may combine the advantages of both conceptions. We explain and clarify the terminology, review the key empirical evidence, and propose an empirical research program that transcends the dichotomy and sets the stage for revealing the mysterious hybrid algorithm of primate vision.", "Keywords": ["Primate vision", "discriminative model", "generative model", "visual inference"], "MeSH terms": [], "Authors": [{"First Name": "Benjamin", "Last Name": "Peters", "Affiliation": "Zuckerman Mind Brain Behavior Institute, Columbia University."}, {"First Name": "James J", "Last Name": "DiCarlo", "Affiliation": "Department of Brain and Cognitive Sciences, MIT."}, {"First Name": "Todd", "Last Name": "Gureckis", "Affiliation": "Department of Psychology, New York University."}, {"First Name": "Ralf", "Last Name": "Haefner", "Affiliation": "Brain and Cognitive Sciences, University of Rochester."}, {"First Name": "Leyla", "Last Name": "Isik", "Affiliation": "Department of Cognitive Science, Johns Hopkins University."}, {"First Name": "Joshua", "Last Name": "Tenenbaum", "Affiliation": "Department of Brain and Cognitive Sciences, MIT."}, {"First Name": "Talia", "Last Name": "Konkle", "Affiliation": "Department of Psychology, Harvard University."}, {"First Name": "Thomas", "Last Name": "Naselaris", "Affiliation": "Department of Neuroscience, University of Minnesota."}, {"First Name": "Kimberly", "Last Name": "Stachenfeld", "Affiliation": "DeepMind."}, {"First Name": "Zenna", "Last Name": "Tavares", "Affiliation": "Zuckerman Mind Brain Behavior Institute, Columbia University."}, {"First Name": "Doris", "Last Name": "Tsao", "Affiliation": "Dept of Molecular & Cell Biology, University of California Berkeley."}, {"First Name": "Ilker", "Last Name": "Yildirim", "Affiliation": "Department of Psychology, Yale University."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Zuckerman Mind Brain Behavior Institute, Columbia University."}], "Journal": "ArXiv", "PubDate": "2024Jan11"}, {"PMID": "38054329", "Title": "Deep neural networks are not a single hypothesis but a language for expressing computational hypotheses.", "Abstract": "An ideal vision model accounts for behavior and neurophysiology in both naturalistic conditions and designed lab experiments. Unlike psychological theories, artificial neural networks (ANNs) actually perform visual tasks and generate testable predictions for arbitrary inputs. These advantages enable ANNs to engage the entire spectrum of the evidence. Failures of particular models drive progress in a vibrant ANN research program of human vision.", "Keywords": [], "MeSH terms": ["Humans", "Neural Networks, Computer", "Language"], "Authors": [{"First Name": "Tal", "Last Name": "Golan", "Affiliation": "Department of Cognitive and Brain Sciences, Ben-Gurion University of the Negev, Be'er Sheva, Israel\u00a0golan.neuro@bgu.ac.ilbrainsandmachines.org."}, {"First Name": "JohnMark", "Last Name": "Taylor", "Affiliation": "Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY, USA\u00a0jt3295@columbia.edu\u00a0hs3110@columbia.edu\u00a0paul.linton@columbia.edu\u00a0nk2765@columbia.edujohnmarktaylor.comhebartlab.comhttps://linton.vision/."}, {"First Name": "Heiko", "Last Name": "Sch\u00fctt", "Affiliation": "Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY, USA\u00a0jt3295@columbia.edu\u00a0hs3110@columbia.edu\u00a0paul.linton@columbia.edu\u00a0nk2765@columbia.edujohnmarktaylor.comhebartlab.comhttps://linton.vision/."}, {"First Name": "Benjamin", "Last Name": "Peters", "Affiliation": "School of Psychology & Neuroscience, University of Glasgow, Glasgow, UK\u00a0benjamin.peters@posteo.de."}, {"First Name": "Rowan P", "Last Name": "Sommers", "Affiliation": "Department of Neurobiology of Language, Max Planck Institute for Psycholinguistics, Nijmegen, The Netherlands\u00a0rowan.sommers@mpi.nl."}, {"First Name": "Katja", "Last Name": "Seeliger", "Affiliation": "Max Planck Institute for Human Cognitive and Brain Sciences, Leipzig, Germany\u00a0katjaseeliger@posteo.de."}, {"First Name": "Adrien", "Last Name": "Doerig", "Affiliation": "Institute of Cognitive Science, University of Osnabr\u00fcck, Osnabr\u00fcck, Germany\u00a0adoerig@uni-osnabrueck.de\u00a0tim.kietzmann@uni-osnabrueck.dekietzmannlab.orgkietzmannlab.org."}, {"First Name": "Paul", "Last Name": "Linton", "Affiliation": "Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY, USA\u00a0jt3295@columbia.edu\u00a0hs3110@columbia.edu\u00a0paul.linton@columbia.edu\u00a0nk2765@columbia.edujohnmarktaylor.comhebartlab.comhttps://linton.vision/."}, {"First Name": "Talia", "Last Name": "Konkle", "Affiliation": "Department of Psychology and Center for Brain Sciences, Harvard University, Cambridge, MA, USA\u00a0talia_konkle@harvard.eduhttps://konklab.fas.harvard.edu/."}, {"First Name": "Marcel", "Last Name": "van Gerven", "Affiliation": "Donders Institute for Brain, Cognition and Behaviour, Nijmegen, The Netherlandsartcogsys.com."}, {"First Name": "Konrad", "Last Name": "Kording", "Affiliation": "Departments of Bioengineering and Neuroscience, University of Pennsylvania, Philadelphia, PA, USA\u00a0koerding@gmail.comkordinglab.com."}, {"First Name": "Blake", "Last Name": "Richards", "Affiliation": "Learning in Machines and Brains Program, CIFAR, Toronto, ON, Canada\u00a0blake.richards@mila.quebeclinclab.org."}, {"First Name": "Tim C", "Last Name": "Kietzmann", "Affiliation": "Institute of Cognitive Science, University of Osnabr\u00fcck, Osnabr\u00fcck, Germany\u00a0adoerig@uni-osnabrueck.de\u00a0tim.kietzmann@uni-osnabrueck.dekietzmannlab.orgkietzmannlab.org."}, {"First Name": "Grace W", "Last Name": "Lindsay", "Affiliation": "Department of Psychology and Center for Data Science, New York University, New York, NY, USA\u00a0grace.lindsay@nyu.edulindsay-lab.github.io."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY, USA\u00a0jt3295@columbia.edu\u00a0hs3110@columbia.edu\u00a0paul.linton@columbia.edu\u00a0nk2765@columbia.edujohnmarktaylor.comhebartlab.comhttps://linton.vision/."}], "Journal": "The Behavioral and brain sciences", "PubDate": "2023Dec06"}, {"PMID": "37658079", "Title": "Extracting and visualizing hidden activations and computational graphs of PyTorch models with TorchLens.", "Abstract": "Deep neural network models (DNNs) are essential to modern AI and provide powerful models of information processing in biological neural networks. Researchers in both neuroscience and engineering are pursuing a better understanding of the internal representations and operations that undergird the successes and failures of DNNs. Neuroscientists additionally evaluate DNNs as models of brain computation by comparing their internal representations to those found in brains. It is therefore essential to have a method to easily and exhaustively extract and characterize the results of the internal operations of any DNN. Many models are implemented in PyTorch, the leading framework for building DNN models. Here we introduce TorchLens, a new open-source Python package for extracting and characterizing hidden-layer activations in PyTorch models. Uniquely among existing approaches to this problem, TorchLens has the following features: (1) it exhaustively extracts the results of all intermediate operations, not just those associated with PyTorch module objects, yielding a full record of every step in the model's computational graph, (2) it provides an intuitive visualization of the model's complete computational graph along with metadata about each computational step in a model's forward pass for further analysis, (3) it contains a built-in validation procedure to algorithmically verify the accuracy of all saved hidden-layer activations, and (4) the approach it uses can be automatically applied to any PyTorch model with no modifications, including models with conditional (if-then) logic in their forward pass, recurrent models, branching models where layer outputs are fed into multiple subsequent layers in parallel, and models with internally generated tensors (e.g., injections of noise). Furthermore, using TorchLens requires minimal additional code, making it easy to incorporate into existing pipelines for model development and analysis, and useful as a pedagogical aid when teaching deep learning concepts. We hope this contribution will help researchers in AI and neuroscience understand the internal representations of DNNs.", "Keywords": [], "MeSH terms": ["Brain", "Cognition", "Engineering", "Metadata", "Neural Networks, Computer"], "Authors": [{"First Name": "JohnMark", "Last Name": "Taylor", "Affiliation": "Zuckerman Mind Brain Behavior Institute, Columbia University, 3227 Broadway, New York, NY, 10027, USA. johnmarkedwardtaylor@gmail.com."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Zuckerman Mind Brain Behavior Institute, Columbia University, 3227 Broadway, New York, NY, 10027, USA."}], "Journal": "Scientific reports", "PubDate": "2023Sep01"}, {"PMID": "37610302", "Title": "Statistical inference on representational geometries.", "Abstract": "Neuroscience has recently made much progress, expanding the complexity of both neural activity measurements and brain-computational models. However, we lack robust methods for connecting theory and experiment by evaluating our new big models with our new big data. Here, we introduce new inference methods enabling researchers to evaluate and compare models based on the accuracy of their predictions of representational geometries: A good model should accurately predict the distances among the neural population representations (e.g. of a set of stimuli). Our inference methods combine novel 2-factor extensions of crossvalidation (to prevent overfitting to either subjects or conditions from inflating our estimates of model accuracy) and bootstrapping (to enable inferential model comparison with simultaneous generalization to both new subjects and new conditions). We validate the inference methods on data where the ground-truth model is known, by simulating data with deep neural networks and by resampling of calcium-imaging and functional MRI data. Results demonstrate that the methods are valid and conclusions generalize correctly. These data analysis methods are available in an open-source Python toolbox (rsatoolbox.readthedocs.io).", "Keywords": ["human", "mouse", "neuroscience", "representational similarity analysis", "statistical inference", "toolbox"], "MeSH terms": ["Humans", "Big Data", "Calcium, Dietary", "Generalization, Psychological", "Neural Networks, Computer", "Neurosciences"], "Authors": [{"First Name": "Heiko H", "Last Name": "Sch\u00fctt", "Affiliation": "Zuckerman Institute, Columbia University, New York, United States."}, {"First Name": "Alexander D", "Last Name": "Kipnis", "Affiliation": "Zuckerman Institute, Columbia University, New York, United States."}, {"First Name": "J\u00f6rn", "Last Name": "Diedrichsen", "Affiliation": "Western University, London, Canada."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Zuckerman Institute, Columbia University, New York, United States."}], "Journal": "eLife", "PubDate": "2023Aug23"}, {"PMID": "37253949", "Title": "The neuroconnectionist research programme.", "Abstract": "Artificial neural networks (ANNs) inspired by biology are beginning to be widely used to model behavioural and neural data, an approach we call 'neuroconnectionism'. ANNs have been not only lauded as the current best models of information processing in the brain but also criticized for failing to account for basic cognitive functions. In this Perspective article, we propose that arguing about the successes and failures of a restricted set of current ANNs is the wrong approach to assess the promise of neuroconnectionism for brain science. Instead, we take inspiration from the philosophy of science, and in particular from Lakatos, who showed that the core of a\u00a0scientific research programme is often not directly falsifiable but should be assessed by its capacity to generate novel insights. Following this view, we present neuroconnectionism as a general research programme centred around ANNs as a computational language for expressing falsifiable theories about brain computation. We describe the core of the programme, the underlying computational framework and its tools for testing specific neuroscientific hypotheses and deriving novel understanding. Taking a longitudinal view, we review past and present neuroconnectionist projects and their responses to challenges and argue that the research programme is highly progressive, generating new and otherwise unreachable insights into the workings of the brain.", "Keywords": [], "MeSH terms": ["Humans", "Neural Networks, Computer", "Brain"], "Authors": [{"First Name": "Adrien", "Last Name": "Doerig", "Affiliation": "Institute of Cognitive Science, University of Osnabr\u00fcck, Osnabr\u00fcck, Germany. adoerig@uni-osnabrueck.de."}, {"First Name": "Rowan P", "Last Name": "Sommers", "Affiliation": "Department of Neurobiology of Language, Max Planck Institute for Psycholinguistics, Nijmegen, The Netherlands."}, {"First Name": "Katja", "Last Name": "Seeliger", "Affiliation": "Max Planck Institute for Human Cognitive and Brain Sciences, Leipzig, Germany."}, {"First Name": "Blake", "Last Name": "Richards", "Affiliation": "Department of Neurology and Neurosurgery, McGill University, Montr\u00e9al, QC, Canada."}, {"First Name": "Jenann", "Last Name": "Ismael", "Affiliation": "Johns Hopkins University, Baltimore, MD, USA."}, {"First Name": "Grace W", "Last Name": "Lindsay", "Affiliation": "New York University, New York, NY, USA."}, {"First Name": "Konrad P", "Last Name": "Kording", "Affiliation": "Learning in Machines and Brains Program, CIFAR, Toronto, ON, Canada."}, {"First Name": "Talia", "Last Name": "Konkle", "Affiliation": "Harvard University, Cambridge, MA, USA."}, {"First Name": "Marcel A J", "Last Name": "van Gerven", "Affiliation": "Donders Institute for Brain, Cognition and Behaviour, Nijmegen, The Netherlands."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Zuckerman Institute, Columbia University, New York, NY, USA."}, {"First Name": "Tim C", "Last Name": "Kietzmann", "Affiliation": "Institute of Cognitive Science, University of Osnabr\u00fcck, Osnabr\u00fcck, Germany."}], "Journal": "Nature reviews. Neuroscience", "PubDate": "2023Jul"}, {"PMID": "36993311", "Title": "TorchLens: A Python package for extracting and visualizing hidden activations of PyTorch models.", "Abstract": "Deep neural network models (DNNs) are essential to modern AI and provide powerful models of information processing in biological neural networks. Researchers in both neuroscience and engineering are pursuing a better understanding of the internal representations and operations that undergird the successes and failures of DNNs. Neuroscientists additionally evaluate DNNs as models of brain computation by comparing their internal representations to those found in brains. It is therefore essential to have a method to easily and exhaustively extract and characterize the results of the internal operations of any DNN. Many models are implemented in PyTorch, the leading framework for building DNN models. Here we introduce TorchLens , a new open-source Python package for extracting and characterizing hidden-layer activations in PyTorch models. Uniquely among existing approaches to this problem, TorchLens has the following features: (1) it exhaustively extracts the results of all intermediate operations, not just those associated with PyTorch module objects, yielding a full record of every step in the model's computational graph, (2) it provides an intuitive visualization of the model's complete computational graph along with metadata about each computational step in a model's forward pass for further analysis, (3) it contains a built-in validation procedure to algorithmically verify the accuracy of all saved hidden-layer activations, and (4) the approach it uses can be automatically applied to any PyTorch model with no modifications, including models with conditional (if-then) logic in their forward pass, recurrent models, branching models where layer outputs are fed into multiple subsequent layers in parallel, and models with internally generated tensors (e.g., injections of noise). Furthermore, using TorchLens requires minimal additional code, making it easy to incorporate into existing pipelines for model development and analysis, and useful as a pedagogical aid when teaching deep learning concepts. We hope this contribution will help researchers in AI and neuroscience understand the internal representations of DNNs.", "Keywords": [], "MeSH terms": [], "Authors": [{"First Name": "JohnMark", "Last Name": "Taylor", "Affiliation": "Zuckerman Mind Brain Behavior Institute, Columbia University (10027)."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Zuckerman Mind Brain Behavior Institute, Columbia University (10027)."}], "Journal": "bioRxiv : the preprint server for biology", "PubDate": "2023Mar18"}, {"PMID": "36759190", "Title": "Deep Neural Networks and Visuo-Semantic Models Explain Complementary Components of Human Ventral-Stream Representational Dynamics.", "Abstract": "Deep neural networks (DNNs) are promising models of the cortical computations supporting human object recognition. However, despite their ability to explain a significant portion of variance in neural data, the agreement between models and brain representational dynamics is far from perfect. We address this issue by asking which representational features are currently unaccounted for in neural time series data, estimated for multiple areas of the ventral stream via source-reconstructed magnetoencephalography data acquired in human participants (nine females, six males) during object viewing. We focus on the ability of visuo-semantic models, consisting of human-generated labels of object features and categories, to explain variance beyond the explanatory power of DNNs alone. We report a gradual reversal in the relative importance of DNN versus visuo-semantic features as ventral-stream object representations unfold over space and time. Although lower-level visual areas are better explained by DNN features starting early in time (at 66 ms after stimulus onset), higher-level cortical dynamics are best accounted for by visuo-semantic features starting later in time (at 146 ms after stimulus onset). Among the visuo-semantic features, object parts and basic categories drive the advantage over DNNs. These results show that a significant component of the variance unexplained by DNNs in higher-level cortical dynamics is structured and can be explained by readily nameable aspects of the objects. We conclude that current DNNs fail to fully capture dynamic representations in higher-level human visual cortex and suggest a path toward more accurate models of ventral-stream computations.SIGNIFICANCE STATEMENT When we view objects such as faces and cars in our visual environment, their neural representations dynamically unfold over time at a millisecond scale. These dynamics reflect the cortical computations that support fast and robust object recognition. DNNs have emerged as a promising framework for modeling these computations but cannot yet fully account for the neural dynamics. Using magnetoencephalography data acquired in human observers during object viewing, we show that readily nameable aspects of objects, such as 'eye', 'wheel', and 'face', can account for variance in the neural dynamics over and above DNNs. These findings suggest that DNNs and humans may in part rely on different object features for visual recognition and provide guidelines for model improvement.", "Keywords": ["categories", "features", "object recognition", "recurrent deep neural networks", "source-reconstructed MEG data", "vision"], "MeSH terms": ["Male", "Female", "Humans", "Semantics", "Pattern Recognition, Visual", "Neural Networks, Computer", "Visual Perception", "Brain", "Brain Mapping", "Magnetic Resonance Imaging"], "Authors": [{"First Name": "Kamila M", "Last Name": "Jozwik", "Affiliation": "Department of Psychology, University of Cambridge, Cambridge CB2 3EB, United Kingdom jozwik.kamila@gmail.com mmur@uwo.ca."}, {"First Name": "Tim C", "Last Name": "Kietzmann", "Affiliation": "Institute of Cognitive Science, University of Osnabr\u00fcck, 49069 Osnabr\u00fcck, Germany."}, {"First Name": "Radoslaw M", "Last Name": "Cichy", "Affiliation": "Department of Education and Psychology, Freie Universit\u00e4t Berlin, 14195 Berlin, Germany."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Zuckerman Mind Brain Behavior Institute, Columbia University, New York, New York 10027."}, {"First Name": "Marieke", "Last Name": "Mur", "Affiliation": "Department of Psychology, Western University, London, Ontario N6A 3K7, Canada jozwik.kamila@gmail.com mmur@uwo.ca."}], "Journal": "The Journal of neuroscience : the official journal of the Society for Neuroscience", "PubDate": "2023Mar08"}, {"PMID": "36711779", "Title": "Emergence of brain-like mirror-symmetric viewpoint tuning in convolutional neural networks.", "Abstract": "Primates can recognize objects despite 3D geometric variations such as in-depth rotations. The computational mechanisms that give rise to such invariances are yet to be fully understood. A curious case of partial invariance occurs in the macaque face-patch AL and in fully connected layers of deep convolutional networks in which neurons respond similarly to mirror-symmetric views (e.g., left and right profiles). Why does this tuning develop? Here, we propose a simple learning-driven explanation for mirror-symmetric viewpoint tuning. We show that mirror-symmetric viewpoint tuning for faces emerges in the fully connected layers of convolutional deep neural networks trained on object recognition tasks, even when the training dataset does not include faces. First, using 3D objects rendered from multiple views as test stimuli, we demonstrate that mirror-symmetric viewpoint tuning in convolutional neural network models is not unique to faces: it emerges for multiple object categories with bilateral symmetry. Second, we show why this invariance emerges in the models. Learning to discriminate among bilaterally symmetric object categories induces reflection-equivariant intermediate representations. AL-like mirror-symmetric tuning is achieved when such equivariant responses are spatially pooled by downstream units with sufficiently large receptive fields. These results explain how mirror-symmetric viewpoint tuning can emerge in neural networks, providing a theory of how they might emerge in the primate brain. Our theory predicts that mirror-symmetric viewpoint tuning can emerge as a consequence of exposure to bilaterally symmetric objects beyond the category of faces, and that it can generalize beyond previously experienced object categories.", "Keywords": [], "MeSH terms": [], "Authors": [{"First Name": "Amirhossein", "Last Name": "Farzmahdi", "Affiliation": "N/A"}, {"First Name": "Wilbert", "Last Name": "Zarco", "Affiliation": "N/A"}, {"First Name": "Winrich", "Last Name": "Freiwald", "Affiliation": "N/A"}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "N/A"}, {"First Name": "Tal", "Last Name": "Golan", "Affiliation": "N/A"}], "Journal": "bioRxiv : the preprint server for biology", "PubDate": "2023Jul06"}, {"PMID": "36376446", "Title": "Disentangling five dimensions of animacy in human brain and behaviour.", "Abstract": "Distinguishing animate from inanimate things is of great behavioural importance. Despite distinct brain and behavioural responses to animate and inanimate things, it remains unclear which object properties drive these responses. Here, we investigate the importance of five object dimensions related to animacy (\"being alive\", \"looking like an animal\", \"having agency\", \"having mobility\", and \"being unpredictable\") in brain (fMRI, EEG) and behaviour (property and similarity judgements) of 19 participants. We used a stimulus set of 128 images, optimized by a genetic algorithm to disentangle these five dimensions. The five dimensions explained much variance in the similarity judgments. Each dimension explained significant variance in the brain representations (except, surprisingly, \"being alive\"), however, to a lesser extent than in behaviour. Different brain regions sensitive to animacy may represent distinct dimensions, either as accessible perceptual stepping stones toward detecting whether something is alive or because they are of behavioural importance in their own right.", "Keywords": [], "MeSH terms": ["Humans", "Pattern Recognition, Visual", "Brain", "Brain Mapping", "Magnetic Resonance Imaging", "Judgment"], "Authors": [{"First Name": "Kamila M", "Last Name": "Jozwik", "Affiliation": "Department of Psychology, University of Cambridge, Cambridge, UK. jozwik.kamila@gmail.com."}, {"First Name": "Elias", "Last Name": "Najarro", "Affiliation": "Digital Design Department, IT University of Copenhagen, Copenhagen, Denmark."}, {"First Name": "Jasper J F", "Last Name": "van den Bosch", "Affiliation": "D\u00e9partement de Psychologie, Universit\u00e9 de Montr\u00e9al, Montreal, Canada."}, {"First Name": "Ian", "Last Name": "Charest", "Affiliation": "D\u00e9partement de Psychologie, Universit\u00e9 de Montr\u00e9al, Montreal, Canada."}, {"First Name": "Radoslaw M", "Last Name": "Cichy", "Affiliation": "Department of Education and Psychology, Freie Universit\u00e4t Berlin, Berlin, Germany."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Zuckerman Mind Brain Behavior Institute, Department of Psychology, Department of Neuroscience, Department of Electrical Engineering, Columbia University, New York, USA."}], "Journal": "Communications biology", "PubDate": "2022Nov14"}, {"PMID": "35767642", "Title": "Face dissimilarity judgments are predicted by representational distance in morphable and image-computable models.", "Abstract": "Human vision is attuned to the subtle differences between individual faces. Yet we lack a quantitative way of predicting how similar two face images look and whether they appear to show the same person. Principal component-based three-dimensional (3D) morphable models are widely used to generate stimuli in face perception research. These models capture the distribution of real human faces in terms of dimensions of physical shape and texture. How well does a \"face space\" based on these dimensions capture the similarity relationships humans perceive among faces? To answer this, we designed a behavioral task to collect dissimilarity and same/different identity judgments for 232 pairs of realistic faces. Stimuli sampled geometric relationships in a face space derived from principal components of 3D shape and texture (Basel face model [BFM]). We then compared a wide range of models in their ability to predict the data, including the BFM from which faces were generated, an active appearance model derived from face photographs, and image-computable models of visual perception. Euclidean distance in the BFM explained both dissimilarity and identity judgments surprisingly well. In a comparison against 16 diverse models, BFM distance was competitive with representational distances in state-of-the-art deep neural networks (DNNs), including novel DNNs trained on BFM synthetic identities or BFM latents. Models capturing the distribution of face shape and texture across individuals are not only useful tools for stimulus generation. They also capture important information about how faces are perceived, suggesting that human face representations are tuned to the statistical distribution of faces.", "Keywords": ["Basel face model", "deep neural networks", "face identification", "face perception", "face similarity"], "MeSH terms": ["Facial Recognition", "Humans", "Judgment", "Neural Networks, Computer", "Visual Perception"], "Authors": [{"First Name": "Kamila M", "Last Name": "Jozwik", "Affiliation": "Department of Psychology, University of Cambridge, Cambridge CB2 3EB, United Kingdom."}, {"First Name": "Jonathan", "Last Name": "O'Keeffe", "Affiliation": "MRC Cognition and Brain Sciences Unit, University of Cambridge, Cambridge CB2 7EF, United Kingdom."}, {"First Name": "Katherine R", "Last Name": "Storrs", "Affiliation": "Department of Experimental Psychology, Justus Liebig University, 35394 Giessen, Germany."}, {"First Name": "Wenxuan", "Last Name": "Guo", "Affiliation": "Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY 10027."}, {"First Name": "Tal", "Last Name": "Golan", "Affiliation": "Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY 10027."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY 10027."}], "Journal": "Proceedings of the National Academy of Sciences of the United States of America", "PubDate": "2022Jul05"}, {"PMID": "34545237", "Title": "Capturing the objects of vision with neural networks.", "Abstract": "Human visual perception carves a scene at its physical joints, decomposing the world into objects, which are selectively attended, tracked and predicted as we engage our surroundings. Object representations emancipate perception from the sensory input, enabling us to keep in mind that which is out of sight and to use perceptual content as a basis for action and symbolic cognition. Human behavioural studies have documented how object representations emerge through grouping, amodal completion, proto-objects and object files. By contrast, deep neural network models of visual object recognition remain largely tethered to sensory input, despite achieving human-level performance at labelling objects. Here, we review related work in both fields and examine how these fields can help each other. The cognitive literature provides a starting point for the development of new experimental tasks that reveal mechanisms of human object perception and serve as benchmarks driving the development of deep neural network models that will put the object into object recognition.", "Keywords": [], "MeSH terms": ["Humans", "Neural Networks, Computer", "Pattern Recognition, Visual", "Recognition, Psychology", "Visual Pathways", "Visual Perception"], "Authors": [{"First Name": "Benjamin", "Last Name": "Peters", "Affiliation": "Mortimer B. Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY, USA. benjamin.peters@posteo.de."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Mortimer B. Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY, USA. n.kriegeskorte@columbia.edu."}], "Journal": "Nature human behaviour", "PubDate": "2021Sep"}, {"PMID": "34522043", "Title": "Neural tuning and representational geometry.", "Abstract": "A central goal of neuroscience is to understand the representations formed by brain activity patterns and their connection to behaviour. The classic approach is to investigate how individual neurons encode stimuli and how their tuning determines the fidelity of the neural representation. Tuning analyses often use the Fisher information to characterize the sensitivity of neural responses to small changes of the stimulus. In recent decades, measurements of large populations of neurons have motivated a complementary approach, which focuses on the information available to linear decoders. The decodable information is captured by the geometry of the representational patterns in the multivariate response space. Here we review neural tuning and representational geometry with the goal of clarifying the relationship between them. The tuning induces the geometry, but different sets of tuned neurons can induce the same geometry. The geometry determines the Fisher information, the mutual information and the behavioural performance of an ideal observer in a range of psychophysical tasks. We argue that future studies can benefit from considering both tuning and geometry to understand neural codes and reveal the connections between stimuli, brain activity and behaviour.", "Keywords": [], "MeSH terms": ["Animals", "Brain", "Humans", "Models, Neurological", "Models, Theoretical", "Neurons"], "Authors": [{"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY, USA. nk2765@columbia.edu."}, {"First Name": "Xue-Xin", "Last Name": "Wei", "Affiliation": "Department of Neuroscience, University of Texas at Austin, Austin, TX, USA. weixx@utexas.edu."}], "Journal": "Nature reviews. Neuroscience", "PubDate": "2021Nov"}, {"PMID": "34272948", "Title": "Diverse Deep Neural Networks All Predict Human Inferior Temporal Cortex Well, After Training and Fitting.", "Abstract": "Deep neural networks (DNNs) trained on object recognition provide the best current models of high-level visual cortex. What remains unclear is how strongly experimental choices, such as network architecture, training, and fitting to brain data, contribute to the observed similarities. Here, we compare a diverse set of nine DNN architectures on their ability to explain the representational geometry of 62 object images in human inferior temporal cortex (hIT), as measured with fMRI. We compare untrained networks to their task-trained counterparts and assess the effect of cross-validated fitting to hIT, by taking a weighted combination of the principal components of features within each layer and, subsequently, a weighted combination of layers. For each combination of training and fitting, we test all models for their correlation with the hIT representational dissimilarity matrix, using independent images and subjects. Trained models outperform untrained models (accounting for 57% more of the explainable variance), suggesting that structured visual features are important for explaining hIT. Model fitting further improves the alignment of DNN and hIT representations (by 124%), suggesting that the relative prevalence of different features in hIT does not readily emerge from the Imagenet object-recognition task used to train the networks. The same models can also explain the disparate representations in primary visual cortex (V1), where stronger weights are given to earlier layers. In each region, all architectures achieved equivalently high performance once trained and fitted. The models' shared properties-deep feedforward hierarchies of spatially restricted nonlinear filters-seem more important than their differences, when modeling human visual representations.", "Keywords": [], "MeSH terms": ["Humans", "Magnetic Resonance Imaging", "Neural Networks, Computer", "Temporal Lobe", "Visual Cortex", "Visual Perception"], "Authors": [{"First Name": "Katherine R", "Last Name": "Storrs", "Affiliation": "Justus Liebig University Giessen, Germany."}, {"First Name": "Tim C", "Last Name": "Kietzmann", "Affiliation": "Donders Institute for Brain, Cognition and Behaviour, Nijmegen, The Netherlands."}, {"First Name": "Alexander", "Last Name": "Walther", "Affiliation": "MRC Cognition and Brain Sciences Unit, Cambridge, United Kingdom."}, {"First Name": "Johannes", "Last Name": "Mehrer", "Affiliation": "MRC Cognition and Brain Sciences Unit, Cambridge, United Kingdom."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Columbia University."}], "Journal": "Journal of cognitive neuroscience", "PubDate": "2021Sep01"}, {"PMID": "34143951", "Title": "Promises and challenges of human computational ethology.", "Abstract": "The movements an organism makes provide insights into its internal states and motives. This principle is the foundation of the new field of computational ethology, which links rich automatic measurements of natural behaviors to motivational states and neural activity. Computational ethology has proven transformative for animal behavioral neuroscience. This success raises the question of whether rich automatic measurements of behavior can similarly drive progress in human neuroscience and psychology. New technologies for capturing and analyzing complex behaviors in real and virtual environments enable us to probe the human brain during naturalistic dynamic interactions with the environment that so far were beyond experimental investigation. Inspired by nonhuman computational ethology, we explore how these new tools can be used to test important questions in human neuroscience. We argue that application of this methodology will help human neuroscience and psychology extend limited behavioral measurements such as reaction time and accuracy, permit novel insights into how the human brain produces behavior, and ultimately reduce the growing measurement gap between human and animal neuroscience.", "Keywords": [], "MeSH terms": ["Brain", "Cognition", "Ethology", "Humans", "Neurosciences"], "Authors": [{"First Name": "Dean", "Last Name": "Mobbs", "Affiliation": "Department of Humanities and Social Sciences, 1200 E. California Blvd., HSS 228-77, Pasadena, CA 91125, USA; Computation and Neural Systems Program at the California Institute of Technology, 1200 E. California Blvd., HSS 228-77, Pasadena, CA 91125, USA. Electronic address: dmobbs@caltech.edu."}, {"First Name": "Toby", "Last Name": "Wise", "Affiliation": "Department of Humanities and Social Sciences, 1200 E. California Blvd., HSS 228-77, Pasadena, CA 91125, USA; Wellcome Centre for Human Neuroimaging, University College London, London, UK; Max Planck UCL Centre for Computational Psychiatry and Ageing Research, University College London, London, UK."}, {"First Name": "Nanthia", "Last Name": "Suthana", "Affiliation": "Department of Psychiatry and Biobehavioral Sciences, Jane and Terry Semel Institute for Neuroscience and Human Behavior, University of California, Los Angeles, Los Angeles, CA, USA; Departments of Neurosurgery, Psychology, and Bioengineering, University of California, Los Angeles, Los Angeles, CA, USA."}, {"First Name": "Noah", "Last Name": "Guzm\u00e1n", "Affiliation": "Computation and Neural Systems Program at the California Institute of Technology, 1200 E. California Blvd., HSS 228-77, Pasadena, CA 91125, USA."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Department of Psychology, Columbia University, New York, NY, USA; Department of Neuroscience, Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY, USA."}, {"First Name": "Joel Z", "Last Name": "Leibo", "Affiliation": "DeepMind, London, UK."}], "Journal": "Neuron", "PubDate": "2021Jul21"}, {"PMID": "34099508", "Title": "Viewing Ambiguous Social Interactions Increases Functional Connectivity between Frontal and Temporal Nodes of the Social Brain.", "Abstract": "Social behavior is coordinated by a network of brain regions, including those involved in the perception of social stimuli and those involved in complex functions, such as inferring perceptual and mental states and controlling social interactions. The properties and function of many of these regions in isolation are relatively well understood, but less is known about how these regions interact while processing dynamic social interactions. To investigate whether the functional connectivity between brain regions is modulated by social context, we collected fMRI data from male monkeys (Macaca mulatta) viewing videos of social interactions labeled as \"affiliative,\" \"aggressive,\" or \"ambiguous.\" We show activation related to the perception of social interactions along both banks of the superior temporal sulcus, parietal cortex, medial and lateral frontal cortex, and the caudate nucleus. Within this network, we show that fronto-temporal functional connectivity is significantly modulated by social context. Crucially, we link the observation of specific behaviors to changes in functional connectivity within our network. Viewing aggressive behavior was associated with a limited increase in temporo-temporal and a weak increase in cingulate-temporal connectivity. By contrast, viewing interactions where the outcome was uncertain was associated with a pronounced increase in temporo-temporal, and cingulate-temporal functional connectivity. We hypothesize that this widespread network synchronization occurs when cingulate and temporal areas coordinate their activity when more difficult social inferences are being made.SIGNIFICANCE STATEMENT Processing social information from our environment requires the activation of several brain regions, which are concentrated within the frontal and temporal lobes. However, little is known about how these areas interact to facilitate the processing of different social interactions. Here we show that functional connectivity within and between the frontal and temporal lobes is modulated by social context. Specifically, we demonstrate that viewing social interactions where the outcome was unclear is associated with increased synchrony within and between the cingulate cortex and temporal cortices. These findings suggest that the coordination between the cingulate and temporal cortices is enhanced when more difficult social inferences are being made.", "Keywords": ["fMRI", "face-processing", "monkey", "social cognition"], "MeSH terms": [], "Authors": [{"First Name": "Matthew", "Last Name": "Ainsworth", "Affiliation": "MRC Cognition and Brain Sciences Unit, University of Cambridge, Cambridge, United Kingdom, CB2 7EF matthew.ainsworth@psy.ox.ac.uk."}, {"First Name": "J\u00e9r\u00f4me", "Last Name": "Sallet", "Affiliation": "Department of Experimental Psychology, University of Oxford, Oxford, United Kingdom, OX2 6GG."}, {"First Name": "Olivier", "Last Name": "Joly", "Affiliation": "MRC Cognition and Brain Sciences Unit, University of Cambridge, Cambridge, United Kingdom, CB2 7EF."}, {"First Name": "Diana", "Last Name": "Kyriazis", "Affiliation": "MRC Cognition and Brain Sciences Unit, University of Cambridge, Cambridge, United Kingdom, CB2 7EF."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "MRC Cognition and Brain Sciences Unit, University of Cambridge, Cambridge, United Kingdom, CB2 7EF."}, {"First Name": "John", "Last Name": "Duncan", "Affiliation": "MRC Cognition and Brain Sciences Unit, University of Cambridge, Cambridge, United Kingdom, CB2 7EF."}, {"First Name": "Urs", "Last Name": "Sch\u00fcffelgen", "Affiliation": "Department of Experimental Psychology, University of Oxford, Oxford, United Kingdom, OX2 6GG."}, {"First Name": "Matthew F S", "Last Name": "Rushworth", "Affiliation": "Department of Experimental Psychology, University of Oxford, Oxford, United Kingdom, OX2 6GG."}, {"First Name": "Andrew H", "Last Name": "Bell", "Affiliation": "MRC Cognition and Brain Sciences Unit, University of Cambridge, Cambridge, United Kingdom, CB2 7EF."}], "Journal": "The Journal of neuroscience : the official journal of the Society for Neuroscience", "PubDate": "2021Jul14"}, {"PMID": "33872341", "Title": "Correction: Inferring exemplar discriminability in brain representations.", "Abstract": "[This corrects the article DOI: 10.1371/journal.pone.0232551.].", "Keywords": [], "MeSH terms": [], "Authors": [{"First Name": "Hamed", "Last Name": "Nili", "Affiliation": "N/A"}, {"First Name": "Alexander", "Last Name": "Walther", "Affiliation": "N/A"}, {"First Name": "Arjen", "Last Name": "Alink", "Affiliation": "N/A"}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "N/A"}], "Journal": "PloS one", "PubDate": "2021"}, {"PMID": "33707658", "Title": "The representational dynamics of perceived voice emotions evolve from categories to dimensions.", "Abstract": "Long-standing affective science theories conceive the perception of emotional stimuli either as discrete categories (for example, an angry voice) or continuous dimensional attributes (for example, an intense and negative vocal emotion). Which position provides a better account is still widely debated. Here we contrast the positions to account for acoustics-independent perceptual and cerebral representational geometry of perceived voice emotions. We combined multimodal imaging of the cerebral response to heard vocal stimuli (using functional magnetic resonance imaging and magneto-encephalography) with post-scanning behavioural assessment of voice emotion perception. By using representational similarity analysis, we find that categories prevail in perceptual and early (less than 200\u2009ms) frontotemporal cerebral representational geometries and that dimensions impinge predominantly on a later limbic-temporal network (at 240\u2009ms and after 500\u2009ms). These results reconcile the two opposing views by reframing the perception of emotions as the interplay of cerebral networks with different representational dynamics that emphasize either categories or dimensions.", "Keywords": [], "MeSH terms": ["Acoustic Stimulation", "Anger", "Arousal", "Emotions", "Humans", "Speech Perception", "Voice"], "Authors": [{"First Name": "Bruno L", "Last Name": "Giordano", "Affiliation": "Institute of Neuroscience of la Timone UMR 7289 Centre National de la Recherche Scientifique and Aix-Marseille University, Marseille, France. bruno.giordano@univ-amu.fr."}, {"First Name": "Caroline", "Last Name": "Whiting", "Affiliation": "Institute of Neuroscience and Psychology, University of Glasgow, Glasgow, UK."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY, USA."}, {"First Name": "Sonja A", "Last Name": "Kotz", "Affiliation": "Faculty of Psychology and Neuroscience, Department of Neuropsychology and Psychopharmacology, Maastricht University, Maastricht, The Netherlands."}, {"First Name": "Joachim", "Last Name": "Gross", "Affiliation": "Institute of Neuroscience and Psychology, University of Glasgow, Glasgow, UK. joachim.gross@wwu.de."}, {"First Name": "Pascal", "Last Name": "Belin", "Affiliation": "Institute of Neuroscience of la Timone UMR 7289 Centre National de la Recherche Scientifique and Aix-Marseille University, Marseille, France. pascal.belin@univ-amu.fr."}], "Journal": "Nature human behaviour", "PubDate": "2021Sep"}, {"PMID": "33593900", "Title": "An ecologically motivated image dataset for deep learning yields better models of human vision.", "Abstract": "Deep neural networks provide the current best models of visual information processing in the primate brain. Drawing on work from computer vision, the most commonly used networks are pretrained on data from the ImageNet Large Scale Visual Recognition Challenge. This dataset comprises images from 1,000 categories, selected to provide a challenging testbed for automated visual object recognition systems. Moving beyond this common practice, we here introduce ecoset, a collection of >1.5 million images from 565 basic-level categories selected to better capture the distribution of objects relevant to humans. Ecoset categories were chosen to be both frequent in linguistic usage and concrete, thereby mirroring important physical objects in the world. We test the effects of training on this ecologically more valid dataset using multiple instances of two neural network architectures: AlexNet and vNet, a novel architecture designed to mimic the progressive increase in receptive field sizes along the human ventral stream. We show that training on ecoset leads to significant improvements in predicting representations in human higher-level visual cortex and perceptual judgments, surpassing the previous state of the art. Significant and highly consistent benefits are demonstrated for both architectures on two separate functional magnetic resonance imaging (fMRI) datasets and behavioral data, jointly covering responses to 1,292 visual stimuli from a wide variety of object categories. These results suggest that computational visual neuroscience may take better advantage of the deep learning framework by using image sets that reflect the human perceptual and cognitive experience. Ecoset and trained network models are openly available to the research community.", "Keywords": ["computational neuroscience", "computer vision", "deep neural networks", "ecological relevance", "human visual system"], "MeSH terms": ["Brain Mapping", "Deep Learning", "Ecology", "Humans", "Models, Neurological", "Neural Networks, Computer", "Pattern Recognition, Visual", "Visual Cortex", "Visual Perception"], "Authors": [{"First Name": "Johannes", "Last Name": "Mehrer", "Affiliation": "MRC Cognition and Brain Sciences Unit, University of Cambridge, CB2 7EF Cambridge, United Kingdom."}, {"First Name": "Courtney J", "Last Name": "Spoerer", "Affiliation": "MRC Cognition and Brain Sciences Unit, University of Cambridge, CB2 7EF Cambridge, United Kingdom."}, {"First Name": "Emer C", "Last Name": "Jones", "Affiliation": "MRC Cognition and Brain Sciences Unit, University of Cambridge, CB2 7EF Cambridge, United Kingdom."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Department of Psychology, Zuckerman Institute, Columbia University, New York, NY 10027."}, {"First Name": "Tim C", "Last Name": "Kietzmann", "Affiliation": "MRC Cognition and Brain Sciences Unit, University of Cambridge, CB2 7EF Cambridge, United Kingdom; t.kietzmann@donders.ru.nl."}], "Journal": "Proceedings of the National Academy of Sciences of the United States of America", "PubDate": "2021Feb23"}, {"PMID": "33452225", "Title": "FFA and OFA Encode Distinct Types of Face Identity Information.", "Abstract": "Faces of different people elicit distinct fMRI patterns in several face-selective regions of the human brain. Here we used representational similarity analysis to investigate what type of identity-distinguishing information is encoded in three face-selective regions: fusiform face area (FFA), occipital face area (OFA), and posterior superior temporal sulcus (pSTS). In a sample of 30 human participants (22 females, 8 males), we used fMRI to measure brain activity patterns elicited by naturalistic videos of famous face identities, and compared their representational distances in each region with models of the differences between identities. We built diverse candidate models, ranging from low-level image-computable properties (pixel-wise, GIST, and Gabor-Jet dissimilarities), through higher-level image-computable descriptions (OpenFace deep neural network, trained to cluster faces by identity), to complex human-rated properties (perceived similarity, social traits, and gender). We found marked differences in the information represented by the FFA and OFA. Dissimilarities between face identities in FFA were accounted for by differences in perceived similarity, Social Traits, Gender, and by the OpenFace network. In contrast, representational distances in OFA were mainly driven by differences in low-level image-based properties (pixel-wise and Gabor-Jet dissimilarities). Our results suggest that, although FFA and OFA can both discriminate between identities, the FFA representation is further removed from the image, encoding higher-level perceptual and social face information.SIGNIFICANCE STATEMENT Recent studies using fMRI have shown that several face-responsive brain regions can distinguish between different face identities. It is however unclear whether these different face-responsive regions distinguish between identities in similar or different ways. We used representational similarity analysis to investigate the computations within three brain regions in response to naturalistically varying videos of face identities. Our results revealed that two regions, the fusiform face area and the occipital face area, encode distinct identity information about faces. Although identity can be decoded from both regions, identity representations in fusiform face area primarily contained information about social traits, gender, and high-level visual features, whereas occipital face area primarily represented lower-level image features.", "Keywords": ["FFA", "OFA", "face identity", "face processing", "representational similarity analysis"], "MeSH terms": ["Brain", "Brain Mapping", "Facial Recognition", "Female", "Humans", "Image Processing, Computer-Assisted", "Magnetic Resonance Imaging", "Male", "Models, Neurological"], "Authors": [{"First Name": "Maria", "Last Name": "Tsantani", "Affiliation": "Division of Psychology, Department of Life Sciences, Brunel University London, Uxbridge, UB8 3PH, United Kingdom maria.tsantani@gmail.com lucia.garrido@city.ac.uk."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Zuckerman Mind Brain Behavior Institute, Columbia University, New York, New York 10027."}, {"First Name": "Katherine", "Last Name": "Storrs", "Affiliation": "Department of Experimental Psychology, Justus Liebig University, Giessen, 35390, Germany."}, {"First Name": "Adrian Lloyd", "Last Name": "Williams", "Affiliation": "Division of Psychology, Department of Life Sciences, Brunel University London, Uxbridge, UB8 3PH, United Kingdom."}, {"First Name": "Carolyn", "Last Name": "McGettigan", "Affiliation": "Speech Hearing and Phonetic Sciences, University College London, London WC1N 1PF, United Kingdom."}, {"First Name": "L\u00facia", "Last Name": "Garrido", "Affiliation": "Division of Psychology, Department of Life Sciences, Brunel University London, Uxbridge, UB8 3PH, United Kingdom maria.tsantani@gmail.com lucia.garrido@city.ac.uk."}], "Journal": "The Journal of neuroscience : the official journal of the Society for Neuroscience", "PubDate": "2021Mar03"}, {"PMID": "33279795", "Title": "Going in circles is the way forward: the role of recurrence in visual inference.", "Abstract": "Biological visual systems exhibit abundant recurrent connectivity. State-of-the-art neural network models for visual recognition, by contrast, rely heavily or exclusively on feedforward computation. Any finite-time recurrent neural network (RNN) can be unrolled along time to yield an equivalent feedforward neural network (FNN). This important insight suggests that computational neuroscientists may not need to engage recurrent computation, and that computer-vision engineers may be limiting themselves to a special case of FNN if they build recurrent models. Here we argue, to the contrary, that FNNs are a special case of RNNs and that computational neuroscientists and engineers should engage recurrence to understand how brains and machines can (1) achieve greater and more flexible computational depth (2) compress complex computations into limited hardware (3) integrate priors and priorities into visual inference through expectation and attention (4) exploit sequential dependencies in their data for better inference and prediction and (5) leverage the power of iterative computation.", "Keywords": [], "MeSH terms": ["Brain", "Neural Networks, Computer", "Vision, Ocular"], "Authors": [{"First Name": "Ruben S", "Last Name": "van Bergen", "Affiliation": "Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY, United States."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY, United States; Department of Psychology, Columbia University, New York, NY, United States; Department of Neuroscience, Columbia University, New York, NY, United States; Affiliated member, Electrical Engineering, Columbia University, New York, NY, United States. Electronic address: n.kriegeskorte@columbia.edu."}], "Journal": "Current opinion in neurobiology", "PubDate": "2020Dec"}, {"PMID": "33229549", "Title": "Controversial stimuli: Pitting neural networks against each other as models of human cognition.", "Abstract": "Distinct scientific theories can make similar predictions. To adjudicate between theories, we must design experiments for which the theories make distinct predictions. Here we consider the problem of comparing deep neural networks as models of human visual recognition. To efficiently compare models' ability to predict human responses, we synthesize controversial stimuli: images for which different models produce distinct responses. We applied this approach to two visual recognition tasks, handwritten digits (MNIST) and objects in small natural images (CIFAR-10). For each task, we synthesized controversial stimuli to maximize the disagreement among models which employed different architectures and recognition algorithms. Human subjects viewed hundreds of these stimuli, as well as natural examples, and judged the probability of presence of each digit/object category in each image. We quantified how accurately each model predicted the human judgments. The best-performing models were a generative analysis-by-synthesis model (based on variational autoencoders) for MNIST and a hybrid discriminative-generative joint energy model for CIFAR-10. These deep neural networks (DNNs), which model the distribution of images, performed better than purely discriminative DNNs, which learn only to map images to labels. None of the candidate models fully explained the human responses. Controversial stimuli generalize the concept of adversarial examples, obviating the need to assume a ground-truth model. Unlike natural images, controversial stimuli are not constrained to the stimulus distribution models are trained on, thus providing severe out-of-distribution tests that reveal the models' inductive biases. Controversial stimuli therefore provide powerful probes of discrepancies between models and human perception.", "Keywords": ["adversarial examples", "deep neural networks", "generative modeling", "optimal experimental design", "visual object recognition"], "MeSH terms": ["Adult", "Cognition", "Deep Learning", "Female", "Humans", "Male", "Models, Neurological", "Normal Distribution", "Pattern Recognition, Automated", "Pattern Recognition, Physiological"], "Authors": [{"First Name": "Tal", "Last Name": "Golan", "Affiliation": "Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY 10027; n.kriegeskorte@columbia.edu tal.golan@columbia.edu."}, {"First Name": "Prashant C", "Last Name": "Raju", "Affiliation": "Department of Computer Science, Columbia University, New York, NY 10027."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY 10027; n.kriegeskorte@columbia.edu tal.golan@columbia.edu."}], "Journal": "Proceedings of the National Academy of Sciences of the United States of America", "PubDate": "2020Nov24"}, {"PMID": "33229525", "Title": "The brain produces mind by modeling.", "Abstract": "N/A", "Keywords": ["brain", "mind", "modeling"], "MeSH terms": ["Brain", "Cognition", "Congresses as Topic", "Humans", "Models, Psychological", "National Academy of Sciences, U.S.", "United States"], "Authors": [{"First Name": "Richard M", "Last Name": "Shiffrin", "Affiliation": "Psychological and Brain Sciences Department, Indiana University, Bloomington, IN 47405; shiffrin@indiana.edu."}, {"First Name": "Danielle S", "Last Name": "Bassett", "Affiliation": "Department of Bioengineering, University of Pennsylvania, Philadelphia, PA 19104."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Zuckerman Mind Behavior Institute, Columbia University, New York, NY 10027."}, {"First Name": "Joshua B", "Last Name": "Tenenbaum", "Affiliation": "Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge, MA 02139-4307."}], "Journal": "Proceedings of the National Academy of Sciences of the United States of America", "PubDate": "2020Nov24"}, {"PMID": "33184286", "Title": "Individual differences among deep neural network models.", "Abstract": "Deep neural networks (DNNs) excel at visual recognition tasks and are increasingly used as a modeling framework for neural computations in the primate brain. Just like individual brains, each DNN has a unique connectivity and representational profile. Here, we investigate individual differences among DNN instances that arise from varying only the random initialization of the network weights. Using tools typically employed in systems neuroscience, we show that this minimal change in initial conditions prior to training leads to substantial differences in intermediate and higher-level network representations despite similar network-level classification performance. We locate the origins of the effects in an under-constrained alignment of category exemplars, rather than misaligned category centroids. These results call into question the common practice of using single networks to derive insights into neural information processing and rather suggest that computational neuroscientists working with DNNs may need to base their inferences on groups of multiple network instances.", "Keywords": [], "MeSH terms": ["Animals", "Brain", "Cognitive Neuroscience", "Individuality", "Neural Networks, Computer"], "Authors": [{"First Name": "Johannes", "Last Name": "Mehrer", "Affiliation": "MRC Cognition and Brain Sciences Unit, University of Cambridge, 15 Chaucer Road, Cambridge, CB2 7EF, UK. johannes.mehrer@mrc-cbu.cam.ac.uk."}, {"First Name": "Courtney J", "Last Name": "Spoerer", "Affiliation": "MRC Cognition and Brain Sciences Unit, University of Cambridge, 15 Chaucer Road, Cambridge, CB2 7EF, UK."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Zuckerman Institute, Columbia University, 3227 Broadway, New York, NY, 10027, USA."}, {"First Name": "Tim C", "Last Name": "Kietzmann", "Affiliation": "MRC Cognition and Brain Sciences Unit, University of Cambridge, 15 Chaucer Road, Cambridge, CB2 7EF, UK. t.kietzmann@donders.ru.nl."}], "Journal": "Nature communications", "PubDate": "2020Nov12"}, {"PMID": "33049407", "Title": "Distinct fronto-temporal substrates of distributional and taxonomic similarity among words: evidence from RSA of BOLD signals.", "Abstract": "A class of semantic theories defines concepts in terms of statistical distributions of lexical items, basing meaning on vectors of word co-occurrence frequencies. A different approach emphasizes abstract hierarchical taxonomic relationships among concepts. However, the functional relevance of these different accounts and how they capture information-encoding of lexical meaning in the brain still remains elusive. We investigated to what extent distributional and taxonomic models explained word-elicited neural responses using cross-validated representational similarity analysis (RSA) of functional magnetic resonance imaging (fMRI) and model comparisons. Our findings show that the brain encodes both types of semantic information, but in distinct cortical regions. Posterior middle temporal regions reflected lexical-semantic similarity based on hierarchical taxonomies, in coherence with the action-relatedness of specific semantic word categories. In contrast, distributional semantics best predicted the representational patterns in left inferior frontal gyrus (LIFG, BA 47). Both representations coexisted in the angular gyrus supporting semantic binding and integration. These results reveal that neuronal networks with distinct cortical distributions across higher-order association cortex encode different representational properties of word meanings. Taxonomy may shape long-term lexical-semantic representations in memory consistently with the sensorimotor details of semantic categories, whilst distributional knowledge in the LIFG (BA 47) may enable semantic combinatorics in the context of language use. Our approach helps to elucidate the nature of semantic representations essential for understanding human language.", "Keywords": ["Co-occurrence statistics", "Conceptual taxonomies", "Language comprehension", "Representational similarity searchlights", "fMRI"], "MeSH terms": ["Adult", "Association", "Brain", "Brain Mapping", "Classification", "Comprehension", "Concept Formation", "Frontal Lobe", "Functional Neuroimaging", "Humans", "Language", "Magnetic Resonance Imaging", "Parietal Lobe", "Semantics", "Temporal Lobe"], "Authors": [{"First Name": "Francesca", "Last Name": "Carota", "Affiliation": "Max-Planck-Institute for Psycholinguistics, Wundtlaan 1, Nijmegen, the Netherlands; Donders Centre for Cognitive NeuroImaging, Radboud University, Kapittelweg 29, 6525 EN Nijmegen, the Netherlands; MRC Cognition and Brain Sciences Unit, 15 Chaucer Road, Cambridge CB2 7EF, United Kingdom; Berlin School of Mind and Brain, Humboldt Universit\u00e4t zu Berlin, Berlin, Germany; Brain Language Laboratory, Department of Philosophy and Humanities, WE4, Freie Universit\u00e4t Berlin, Berlin, Germany. Electronic address: francesca.carota@mpi.nl."}, {"First Name": "Hamed", "Last Name": "Nili", "Affiliation": "MRC Cognition and Brain Sciences Unit, 15 Chaucer Road, Cambridge CB2 7EF, United Kingdom; Department of Experimental Psychology, University of Oxford, Tinbergen Building, 9 South Parks Road, Oxford OX1 3UD, United Kingdom."}, {"First Name": "Friedemann", "Last Name": "Pulverm\u00fcller", "Affiliation": "MRC Cognition and Brain Sciences Unit, 15 Chaucer Road, Cambridge CB2 7EF, United Kingdom; Berlin School of Mind and Brain, Humboldt Universit\u00e4t zu Berlin, Berlin, Germany; Brain Language Laboratory, Department of Philosophy and Humanities, WE4, Freie Universit\u00e4t Berlin, Berlin, Germany."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "MRC Cognition and Brain Sciences Unit, 15 Chaucer Road, Cambridge CB2 7EF, United Kingdom; Cognitive Imaging at the Zuckerman Mind Brain Behavior Institute, Columbia University, Jerome L. Greene Science Center, 3227 Broadway, L3-064, 9834 New York, NY 10027, United States."}], "Journal": "NeuroImage", "PubDate": "2021Jan01"}, {"PMID": "33006992", "Title": "Recurrent neural networks can explain flexible trading of speed and accuracy in biological vision.", "Abstract": "Deep feedforward neural network models of vision dominate in both computational neuroscience and engineering. The primate visual system, by contrast, contains abundant recurrent connections. Recurrent signal flow enables recycling of limited computational resources over time, and so might boost the performance of a physically finite brain or model. Here we show: (1) Recurrent convolutional neural network models outperform feedforward convolutional models matched in their number of parameters in large-scale visual recognition tasks on natural images. (2) Setting a confidence threshold, at which recurrent computations terminate and a decision is made, enables flexible trading of speed for accuracy. At a given confidence threshold, the model expends more time and energy on images that are harder to recognise, without requiring additional parameters for deeper computations. (3) The recurrent model's reaction time for an image predicts the human reaction time for the same image better than several parameter-matched and state-of-the-art feedforward models. (4) Across confidence thresholds, the recurrent model emulates the behaviour of feedforward control models in that it achieves the same accuracy at approximately the same computational cost (mean number of floating-point operations). However, the recurrent model can be run longer (higher confidence threshold) and then outperforms parameter-matched feedforward comparison models. These results suggest that recurrent connectivity, a hallmark of biological visual systems, may be essential for understanding the accuracy, flexibility, and dynamics of human visual recognition.", "Keywords": [], "MeSH terms": ["Adult", "Computational Biology", "Female", "Humans", "Male", "Models, Neurological", "Neural Networks, Computer", "Reaction Time", "Vision, Ocular", "Visual Perception", "Young Adult"], "Authors": [{"First Name": "Courtney J", "Last Name": "Spoerer", "Affiliation": "Medical Research Council Cognition and Brain Sciences Unit, University of Cambridge, Cambridge, United Kingdom."}, {"First Name": "Tim C", "Last Name": "Kietzmann", "Affiliation": "Medical Research Council Cognition and Brain Sciences Unit, University of Cambridge, Cambridge, United Kingdom."}, {"First Name": "Johannes", "Last Name": "Mehrer", "Affiliation": "Medical Research Council Cognition and Brain Sciences Unit, University of Cambridge, Cambridge, United Kingdom."}, {"First Name": "Ian", "Last Name": "Charest", "Affiliation": "School of Psychology and Centre for Human Brain Health, University of Birmingham, United Kingdom."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Department of Psychology, Department of Neuroscience, Department of Electrical Engineering, Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY, USA."}], "Journal": "PLoS computational biology", "PubDate": "2020Oct"}, {"PMID": "32520962", "Title": "Inferring exemplar discriminability in brain representations.", "Abstract": "Representational distinctions within categories are important in all perceptual modalities and also in cognitive and motor representations. Recent pattern-information studies of brain activity have used condition-rich designs to sample the stimulus space more densely. To test whether brain response patterns discriminate among a set of stimuli (e.g. exemplars within a category) with good sensitivity, we can pool statistical evidence over all pairwise comparisons. Here we describe a wide range of statistical tests of exemplar discriminability and assess the validity (specificity) and power (sensitivity) of each test. The tests include previously used and novel, parametric and nonparametric tests, which treat subject as a random or fixed effect, and are based on different dissimilarity measures, different test statistics, and different inference procedures. We use simulated and real data to determine which tests are valid and which are most sensitive. A popular test statistic reflecting exemplar information is the exemplar discriminability index (EDI), which is defined as the average of the pattern dissimilarity estimates between different exemplars minus the average of the pattern dissimilarity estimates between repetitions of identical exemplars. The popular across-subject t test of the EDI (typically using correlation distance as the pattern dissimilarity measure) requires the assumption that the EDI is 0-mean normal under H0. Although this assumption is not strictly true, our simulations suggest that the test controls the false-positives rate at the nominal level, and is thus valid, in practice. However, test statistics based on average Mahalanobis distances or average linear-discriminant t values (both accounting for the multivariate error covariance among responses) are substantially more powerful for both random- and fixed-effects inference. Unlike average cross-validated distances, the EDI is sensitive to differences between the distributions associated with different exemplars (e.g. greater variability for some exemplars than for others), which complicates its interpretation. We suggest preferred procedures for safely and sensitively detecting subtle pattern differences between exemplars.", "Keywords": [], "MeSH terms": ["Adult", "Brain", "Brain Mapping", "Computer Simulation", "Data Interpretation, Statistical", "Female", "Humans", "Magnetic Resonance Imaging", "Male", "Pattern Recognition, Automated", "Sensitivity and Specificity", "Visual Perception", "Young Adult"], "Authors": [{"First Name": "Hamed", "Last Name": "Nili", "Affiliation": "Wellcome Centre for Integrative Neuroimaging, University of Oxford, Oxford, England, United Kingdom."}, {"First Name": "Alexander", "Last Name": "Walther", "Affiliation": "MRC Cognition and Brain Sciences Unit, Cambridge, England, United Kingdom."}, {"First Name": "Arjen", "Last Name": "Alink", "Affiliation": "University Medical Center Hamburg-Eppendorf, Hamburg, Germany."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Zuckerman Institute, Columbia University, New York, NY, United States of America."}], "Journal": "PloS one", "PubDate": "2020"}, {"PMID": "32366956", "Title": "Rapid event-related, BOLD fMRI, non-human primates (NHP): choose two out of three.", "Abstract": "Human functional magnetic resonance imaging (fMRI) typically employs the blood-oxygen-level-dependent (BOLD) contrast mechanism. In non-human primates (NHP), contrast enhancement is possible using monocrystalline iron-oxide nanoparticles (MION) contrast agent, which has a more temporally extended response function. However, using BOLD fMRI in NHP is desirable for interspecies comparison, and the BOLD signal's faster response function promises to be beneficial for rapid event-related (rER) designs. Here, we used rER BOLD fMRI in macaque monkeys while viewing real-world images, and found visual responses and category selectivity consistent with previous studies. However, activity estimates were very noisy, suggesting that the lower contrast-to-noise ratio of BOLD, suboptimal behavioural performance, and motion artefacts, in combination, render rER BOLD fMRI challenging in NHP. Previous studies have shown that rER fMRI is possible in macaques with MION, despite MION's prolonged response function. To understand this, we conducted simulations of the BOLD and MION response during rER, and found that no matter how fast the design, the greater amplitude of the MION response outweighs the contrast loss caused by greater temporal smoothing. We conclude that although any two of the three elements (rER, BOLD, NHP) have been shown to work well, the combination of all three is particularly challenging.", "Keywords": [], "MeSH terms": ["Animals", "Brain", "Contrast Media", "Evoked Potentials", "Ferrosoferric Oxide", "Macaca mulatta", "Magnetic Resonance Imaging", "Male", "Nanoparticles"], "Authors": [{"First Name": "Vassilis", "Last Name": "Pelekanos", "Affiliation": "Medical Research Council, Cognition and Brain Sciences Unit, University of Cambridge, Cambridge, UK. vassilis.pelekanos@nottingham.ac.uk."}, {"First Name": "Robert M", "Last Name": "Mok", "Affiliation": "Medical Research Council, Cognition and Brain Sciences Unit, University of Cambridge, Cambridge, UK."}, {"First Name": "Olivier", "Last Name": "Joly", "Affiliation": "Medical Research Council, Cognition and Brain Sciences Unit, University of Cambridge, Cambridge, UK."}, {"First Name": "Matthew", "Last Name": "Ainsworth", "Affiliation": "Medical Research Council, Cognition and Brain Sciences Unit, University of Cambridge, Cambridge, UK."}, {"First Name": "Diana", "Last Name": "Kyriazis", "Affiliation": "Medical Research Council, Cognition and Brain Sciences Unit, University of Cambridge, Cambridge, UK."}, {"First Name": "Maria G", "Last Name": "Kelly", "Affiliation": "Department of Experimental Psychology, University of Oxford, Oxford, UK."}, {"First Name": "Andrew H", "Last Name": "Bell", "Affiliation": "Medical Research Council, Cognition and Brain Sciences Unit, University of Cambridge, Cambridge, UK."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Medical Research Council, Cognition and Brain Sciences Unit, University of Cambridge, Cambridge, UK."}], "Journal": "Scientific reports", "PubDate": "2020May04"}, {"PMID": "31659335", "Title": "A deep learning framework for neuroscience.", "Abstract": "Systems neuroscience seeks explanations for how the brain implements a wide variety of perceptual, cognitive and motor tasks. Conversely, artificial intelligence attempts to design computational systems based on the tasks they will have to solve. In artificial neural networks, the three components specified by design are the objective functions, the learning rules and the architectures. With the growing success of deep learning, which utilizes brain-inspired architectures, these three designed components have increasingly become central to how we model, engineer and optimize complex artificial learning systems. Here we argue that a greater focus on these components would also benefit systems neuroscience. We give examples of how this optimization-based framework can drive theoretical and experimental progress in neuroscience. We contend that this principled perspective on systems neuroscience will help to generate more rapid progress.", "Keywords": [], "MeSH terms": ["Animals", "Artificial Intelligence", "Brain", "Deep Learning", "Humans", "Neural Networks, Computer"], "Authors": [{"First Name": "Blake A", "Last Name": "Richards", "Affiliation": "Mila, Montr\u00e9al, Quebec, Canada. blake.richards@mcgill.ca."}, {"First Name": "Timothy P", "Last Name": "Lillicrap", "Affiliation": "DeepMind, Inc., London, UK."}, {"First Name": "Philippe", "Last Name": "Beaudoin", "Affiliation": "Element AI, Montr\u00e9al, QC, Canada."}, {"First Name": "Yoshua", "Last Name": "Bengio", "Affiliation": "Mila, Montr\u00e9al, Quebec, Canada."}, {"First Name": "Rafal", "Last Name": "Bogacz", "Affiliation": "MRC Brain Network Dynamics Unit, University of Oxford, Oxford, UK."}, {"First Name": "Amelia", "Last Name": "Christensen", "Affiliation": "Department of Electrical Engineering, Stanford University, Stanford, CA, USA."}, {"First Name": "Claudia", "Last Name": "Clopath", "Affiliation": "Department of Bioengineering, Imperial College London, London, UK."}, {"First Name": "Rui Ponte", "Last Name": "Costa", "Affiliation": "Computational Neuroscience Unit, School of Computer Science, Electrical and Electronic Engineering, and Engineering Maths, University of Bristol, Bristol, UK."}, {"First Name": "Archy", "Last Name": "de Berker", "Affiliation": "Element AI, Montr\u00e9al, QC, Canada."}, {"First Name": "Surya", "Last Name": "Ganguli", "Affiliation": "Department of Applied Physics, Stanford University, Stanford, CA, USA."}, {"First Name": "Colleen J", "Last Name": "Gillon", "Affiliation": "Department of Biological Sciences, University of Toronto Scarborough, Toronto, Ontario, Canada."}, {"First Name": "Danijar", "Last Name": "Hafner", "Affiliation": "Google Brain, Mountain View, CA, USA."}, {"First Name": "Adam", "Last Name": "Kepecs", "Affiliation": "Cold Spring Harbor Laboratory, Cold Spring Harbor, NY, USA."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Department of Psychology and Neuroscience, Columbia University, New York, NY, USA."}, {"First Name": "Peter", "Last Name": "Latham", "Affiliation": "Gatsby Computational Neuroscience Unit, University College London, London, UK."}, {"First Name": "Grace W", "Last Name": "Lindsay", "Affiliation": "Zuckerman Mind Brain Behavior Institute, Columbia University, New York, New York, USA."}, {"First Name": "Kenneth D", "Last Name": "Miller", "Affiliation": "Zuckerman Mind Brain Behavior Institute, Columbia University, New York, New York, USA."}, {"First Name": "Richard", "Last Name": "Naud", "Affiliation": "University of Ottawa Brain and Mind Institute, Ottawa, Ontario, Canada."}, {"First Name": "Christopher C", "Last Name": "Pack", "Affiliation": "Department of Neurology & Neurosurgery, McGill University, Montr\u00e9al, Quebec, Canada."}, {"First Name": "Panayiota", "Last Name": "Poirazi", "Affiliation": "Institute of Molecular Biology and Biotechnology (IMBB), Foundation for Research and Technology-Hellas (FORTH), Heraklion, Crete, Greece."}, {"First Name": "Pieter", "Last Name": "Roelfsema", "Affiliation": "Department of Vision & Cognition, Netherlands Institute for Neuroscience, Amsterdam, Netherlands."}, {"First Name": "Jo\u00e3o", "Last Name": "Sacramento", "Affiliation": "Institute of Neuroinformatics, ETH Z\u00fcrich and University of Z\u00fcrich, Z\u00fcrich, Switzerland."}, {"First Name": "Andrew", "Last Name": "Saxe", "Affiliation": "Department of Experimental Psychology, University of Oxford, Oxford, UK."}, {"First Name": "Benjamin", "Last Name": "Scellier", "Affiliation": "Mila, Montr\u00e9al, Quebec, Canada."}, {"First Name": "Anna C", "Last Name": "Schapiro", "Affiliation": "Department of Psychology, University of Pennsylvania, Philadelphia, PA, USA."}, {"First Name": "Walter", "Last Name": "Senn", "Affiliation": "Department of Physiology, Universit\u00e4t Bern, Bern, Switzerland."}, {"First Name": "Greg", "Last Name": "Wayne", "Affiliation": "DeepMind, Inc., London, UK."}, {"First Name": "Daniel", "Last Name": "Yamins", "Affiliation": "Department of Psychology, Stanford University, Stanford, CA, USA."}, {"First Name": "Friedemann", "Last Name": "Zenke", "Affiliation": "Friedrich Miescher Institute for Biomedical Research, Basel, Switzerland."}, {"First Name": "Joel", "Last Name": "Zylberberg", "Affiliation": "Canadian Institute for Advanced Research, Toronto, Ontario, Canada."}, {"First Name": "Denis", "Last Name": "Therien", "Affiliation": "Element AI, Montr\u00e9al, QC, Canada."}, {"First Name": "Konrad P", "Last Name": "Kording", "Affiliation": "Canadian Institute for Advanced Research, Toronto, Ontario, Canada."}], "Journal": "Nature neuroscience", "PubDate": "2019Nov"}, {"PMID": "31613918", "Title": "Analysing linear multivariate pattern transformations in neuroimaging data.", "Abstract": "Most connectivity metrics in neuroimaging research reduce multivariate activity patterns in regions-of-interests (ROIs) to one dimension, which leads to a loss of information. Importantly, it prevents us from investigating the transformations between patterns in different ROIs. Here, we applied linear estimation theory in order to robustly estimate the linear transformations between multivariate fMRI patterns with a cross-validated ridge regression approach. We used three functional connectivity metrics that describe different features of these voxel-by-voxel mappings: goodness-of-fit, sparsity and pattern deformation. The goodness-of-fit describes the degree to which the patterns in an input region can be described as a linear transformation of patterns in an output region. The sparsity metric, which relies on a Monte Carlo procedure, was introduced in order to test whether the transformation mostly consists of one-to-one mappings between voxels in different regions. Furthermore, we defined a metric for pattern deformation, i.e. the degree to which the transformation rotates or rescales the input patterns. As a proof of concept, we applied these metrics to an event-related fMRI data set consisting of four subjects that has been used in previous studies. We focused on the transformations from early visual cortex (EVC) to inferior temporal cortex (ITC), fusiform face area (FFA) and parahippocampal place area (PPA). Our results suggest that the estimated linear mappings explain a significant amount of response variance in the three output ROIs. The transformation from EVC to ITC shows the highest goodness-of-fit, and those from EVC to FFA and PPA show the expected preference for faces and places as well as animate and inanimate objects, respectively. The pattern transformations are sparse, but sparsity is lower than would have been expected for one-to-one mappings, thus suggesting the presence of one-to-few voxel mappings. The mappings are also characterised by different levels of pattern deformations, thus indicating that the transformations differentially amplify or dampen certain dimensions of the input patterns. While our results are only based on a small number of subjects, they show that our pattern transformation metrics can describe novel aspects of multivariate functional connectivity in neuroimaging data.", "Keywords": [], "MeSH terms": ["Adult", "Female", "Humans", "Magnetic Resonance Imaging", "Monte Carlo Method", "Multivariate Analysis", "Neuroimaging", "Pattern Recognition, Visual", "Regression Analysis"], "Authors": [{"First Name": "Alessio", "Last Name": "Basti", "Affiliation": "Department of Neuroscience, Imaging and Clinical Sciences, University of Chieti-Pescara, Chieti, Italy."}, {"First Name": "Marieke", "Last Name": "Mur", "Affiliation": "MRC Cognition and Brain Sciences Unit, University of Cambridge, Cambridge, England, United Kingdom."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Department of Psychology, Department of Neuroscience, Department of Electrical Engineering, Zuckerman Mind Brain Behavior Institute, Columbia University, New York, United States of America."}, {"First Name": "Vittorio", "Last Name": "Pizzella", "Affiliation": "Department of Neuroscience, Imaging and Clinical Sciences, University of Chieti-Pescara, Chieti, Italy."}, {"First Name": "Laura", "Last Name": "Marzetti", "Affiliation": "Department of Neuroscience, Imaging and Clinical Sciences, University of Chieti-Pescara, Chieti, Italy."}, {"First Name": "Olaf", "Last Name": "Hauk", "Affiliation": "MRC Cognition and Brain Sciences Unit, University of Cambridge, Cambridge, England, United Kingdom."}], "Journal": "PloS one", "PubDate": "2019"}, {"PMID": "31591217", "Title": "Recurrence is required to capture the representational dynamics of the human visual system.", "Abstract": "The human visual system is an intricate network of brain regions that enables us to recognize the world around us. Despite its abundant lateral and feedback connections, object processing is commonly viewed and studied as a feedforward process. Here, we measure and model the rapid representational dynamics across multiple stages of the human ventral stream using time-resolved brain imaging and deep learning. We observe substantial representational transformations during the first 300 ms of processing within and across ventral-stream regions. Categorical divisions emerge in sequence, cascading forward and in reverse across regions, and Granger causality analysis suggests bidirectional information flow between regions. Finally, recurrent deep neural network models clearly outperform parameter-matched feedforward models in terms of their ability to capture the multiregion cortical dynamics. Targeted virtual cooling experiments on the recurrent deep network models further substantiate the importance of their lateral and top-down connections. These results establish that recurrent models are required to understand information processing in the human ventral stream.", "Keywords": ["deep recurrent neural networks", "magnetoencephalography", "object recognition", "representational dynamics", "virtual cooling"], "MeSH terms": ["Adult", "Deep Learning", "Feedback, Sensory", "Female", "Humans", "Magnetoencephalography", "Models, Neurological", "Nerve Net", "Visual Pathways", "Visual Perception"], "Authors": [{"First Name": "Tim C", "Last Name": "Kietzmann", "Affiliation": "MRC Cognition and Brain Sciences Unit, University of Cambridge, Cambridge CB2 7EF, United Kingdom; tim.kietzmann@mrc-cbu.cam.ac.uk."}, {"First Name": "Courtney J", "Last Name": "Spoerer", "Affiliation": "MRC Cognition and Brain Sciences Unit, University of Cambridge, Cambridge CB2 7EF, United Kingdom."}, {"First Name": "Lynn K A", "Last Name": "S\u00f6rensen", "Affiliation": "Department of Psychology, University of Amsterdam, 1018 WD Amsterdam, The Netherlands."}, {"First Name": "Radoslaw M", "Last Name": "Cichy", "Affiliation": "Department of Education and Psychology, Freie Universit\u00e4t Berlin, 14195 Berlin, Germany."}, {"First Name": "Olaf", "Last Name": "Hauk", "Affiliation": "MRC Cognition and Brain Sciences Unit, University of Cambridge, Cambridge CB2 7EF, United Kingdom."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Department of Psychology, Columbia University, New York, NY 10027."}], "Journal": "Proceedings of the National Academy of Sciences of the United States of America", "PubDate": "2019Oct22"}, {"PMID": "31299368", "Title": "Faces and voices in the brain: A modality-general person-identity representation in superior temporal sulcus.", "Abstract": "Face-selective and voice-selective brain regions have been shown to represent face-identity and voice-identity, respectively. Here we investigated whether there are modality-general person-identity representations in the brain that can be driven by either a face or a voice, and that invariantly represent naturalistically varying face videos and voice recordings of the same identity. Models of face and voice integration suggest that such representations could exist in multimodal brain regions, and in unimodal regions via direct coupling between face- and voice-selective regions. Therefore, in this study we used fMRI to measure brain activity patterns elicited by the faces and voices of familiar people in face-selective, voice-selective, and person-selective multimodal brain regions. We used representational similarity analysis to (1) compare representational geometries (i.e. representational dissimilarity matrices) of face- and voice-elicited identities, and to (2) investigate the degree to which pattern discriminants for pairs of identities generalise from one modality to the other. We did not find any evidence of similar representational geometries across modalities in any of our regions of interest. However, our results showed that pattern discriminants that were trained to discriminate pairs of identities from their faces could also discriminate the respective voices (and vice-versa) in the right posterior superior temporal sulcus (rpSTS). Our findings suggest that the rpSTS is a person-selective multimodal region that shows a modality-general person-identity representation and integrates face and voice identity information.", "Keywords": ["Face recognition", "Multisensory processing", "Person-identity recognition", "Representational similarity analysis", "Voice recognition"], "MeSH terms": ["Adult", "Auditory Perception", "Facial Recognition", "Female", "Humans", "Magnetic Resonance Imaging", "Male", "Recognition, Psychology", "Temporal Lobe", "Voice", "Young Adult"], "Authors": [{"First Name": "Maria", "Last Name": "Tsantani", "Affiliation": "Division of Psychology, Department of Life Sciences, Brunel University London, Kingston Lane, Uxbridge, UB8 3PH, UK. Electronic address: maria.tsantani@gmail.com."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Zuckerman Mind Brain Behavior Institute, Columbia University, 3227 Broadway, New York, NY, 10027, USA."}, {"First Name": "Carolyn", "Last Name": "McGettigan", "Affiliation": "Speech Hearing and Phonetic Sciences, University College London, 2 Wakefield St, Kings Cross, London, WC1N 1PJ, UK."}, {"First Name": "L\u00facia", "Last Name": "Garrido", "Affiliation": "Division of Psychology, Department of Life Sciences, Brunel University London, Kingston Lane, Uxbridge, UB8 3PH, UK. Electronic address: garridolucia@gmail.com."}], "Journal": "NeuroImage", "PubDate": "2019Nov01"}, {"PMID": "31283895", "Title": "Peeling the Onion of Brain Representations.", "Abstract": "The brain's function is to enable adaptive behavior in the world. To this end, the brain processes information about the world. The concept of representation links the information processed by the brain back to the world and enables us to understand what the brain does at a functional level. The appeal of making the connection between brain activity and what it represents has been irresistible to neuroscience, despite the fact that representational interpretations pose several challenges: We must define which aspects of brain activity matter, how the code works, and how it supports computations that contribute to adaptive behavior. It has been suggested that we might drop representational language altogether and seek to understand the brain, more simply, as a dynamical system. In this review, we argue that the concept of representation provides a useful link between dynamics and computational function and ask which aspects of brain activity should be analyzed to achieve a representational understanding. We peel the onion of brain representations in search of the layers (the aspects of brain activity) that matter to computation. The article provides an introduction to the motivation and mathematics of representational models, a critical discussion of their assumptions and limitations, and a preview of future directions in this area.", "Keywords": ["brain representations", "decoding", "encoding", "neural code", "pattern component model", "representational similarity analysis"], "MeSH terms": ["Brain", "Brain Mapping", "Cognition", "Humans", "Magnetic Resonance Imaging", "Models, Neurological"], "Authors": [{"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Zuckerman Mind Brain Behavior Institute and Departments of Psychology, Neuroscience, and Electrical Engineering, Columbia University, New York, New York 10027, USA; email: n.kriegeskorte@columbia.edu."}, {"First Name": "J\u00f6rn", "Last Name": "Diedrichsen", "Affiliation": "Brain and Mind Institute and Departments of Computer Science and Statistical and Actuarial Sciences, Western University, London, Ontario N6A 3K7, Canada; email: jdiedric@uwo.ca."}], "Journal": "Annual review of neuroscience", "PubDate": "2019Jul08"}, {"PMID": "31097360", "Title": "Rapid Invariant Encoding of Scene Layout in Human OPA.", "Abstract": "Successful visual navigation requires a sense of the geometry of the local environment. How do our brains extract this information from retinal images? Here we visually presented scenes with all possible combinations of five scene-bounding elements (left, right, and back walls; ceiling; floor) to human subjects during functional magnetic resonance imaging (fMRI) and magnetoencephalography (MEG). The fMRI response patterns in the scene-responsive occipital place area\u00a0(OPA) reflected scene layout with invariance to changes in surface texture. This result contrasted sharply with the primary visual cortex (V1), which reflected low-level image features of the stimuli, and the parahippocampal place area (PPA), which showed better texture than layout decoding. MEG indicated that the texture-invariant scene layout representation is computed from visual input within \u223c100\u00a0ms, suggesting a rapid computational mechanism. Taken together, these results suggest that the cortical representation underlying our instant sense of the environmental geometry is located in the OPA.", "Keywords": ["MEG", "fMRI", "navigation", "scene elements", "scene perception", "spatial layout"], "MeSH terms": ["Adult", "Brain Mapping", "Female", "Hippocampus", "Humans", "Magnetic Resonance Imaging", "Magnetoencephalography", "Male", "Middle Aged", "Models, Neurological", "Occipital Lobe", "Orientation", "Photic Stimulation", "Visual Cortex", "Visual Perception", "Young Adult"], "Authors": [{"First Name": "Linda", "Last Name": "Henriksson", "Affiliation": "Department of Neuroscience and Biomedical Engineering, Aalto University, 02150 Espoo, Finland; AMI Centre, MEG Core, ABL, Aalto NeuroImaging, Aalto University, 02150 Espoo, Finland. Electronic address: linda.henriksson@aalto.fi."}, {"First Name": "Marieke", "Last Name": "Mur", "Affiliation": "MRC Cognition and Brain Sciences Unit, University of Cambridge, Cambridge CB2 7EF, UK; Department of Psychology, Brain and Mind Institute, Western University, London, ON N6A 3K7, Canada."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "MRC Cognition and Brain Sciences Unit, University of Cambridge, Cambridge CB2 7EF, UK; Department of Psychology, Department of Neuroscience, and Department of Electrical Engineering, Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY 10032, USA."}], "Journal": "Neuron", "PubDate": "2019Jul03"}, {"PMID": "31039527", "Title": "Interpreting encoding and decoding models.", "Abstract": "Encoding and decoding models are widely used in systems, cognitive, and computational neuroscience to make sense of brain-activity data. However, the interpretation of their results requires care. Decoding models can help reveal whether particular information is present in a brain region in a format the decoder can exploit. Encoding models make comprehensive predictions about representational spaces. In the context of sensory experiments, where stimuli are experimentally controlled, encoding models enable us to test and compare brain-computational theories. Encoding and decoding models typically include fitted linear-model components. Sometimes the weights of the fitted linear combinations are interpreted as reflecting, in an encoding model, the contribution of different sensory features to the representation or, in a decoding model, the contribution of different measured brain responses to a decoded feature. Such interpretations can be problematic when the predictor variables or their noise components are correlated and when priors (or penalties) are used to regularize the fit. Encoding and decoding models are evaluated in terms of their generalization performance. The correct interpretation depends on the level of generalization a model achieves (e.g. to new response measurements for the same stimuli, to new stimuli from the same population, or to stimuli from a different population). Significant decoding or encoding performance of a single model (at whatever level of generality) does not provide strong constraints for theory. Many models must be tested and inferentially compared for analyses to drive theoretical progress.", "Keywords": [], "MeSH terms": ["Brain", "Brain Mapping", "Linear Models", "Models, Neurological"], "Authors": [{"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Department of Psychology, Department of Neuroscience, Department of Electrical Engineering, Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY, United States. Electronic address: nk2765@columbia.edu."}, {"First Name": "Pamela K", "Last Name": "Douglas", "Affiliation": "Center for Cognitive Neuroscience, University of California, Los Angeles, CA, United States."}], "Journal": "Current opinion in neurobiology", "PubDate": "2019Apr"}, {"PMID": "30939301", "Title": "Neural network models and deep learning.", "Abstract": "Originally inspired by neurobiology, deep neural network models have become a powerful tool of machine learning and artificial intelligence. They can approximate functions and dynamics by learning from examples. Here we give a brief introduction to neural network models and deep learning for biologists. We introduce feedforward and recurrent networks and explain the expressive power of this modeling framework and the backpropagation algorithm for setting the parameters. Finally, we consider how deep neural network models might help us understand brain computation.", "Keywords": [], "MeSH terms": ["Animals", "Brain", "Deep Learning", "Humans", "Neural Networks, Computer"], "Authors": [{"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Department of Psychology, Columbia University, New York, NY 10027, USA; Department of Neuroscience, Columbia University, New York, NY 10027, USA; Department of Electrical Engineering, Columbia University, New York, NY 10027, USA; Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY 10027, USA. Electronic address: n.kriegeskorte@columbia.edu."}, {"First Name": "Tal", "Last Name": "Golan", "Affiliation": "Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY 10027, USA. Electronic address: tal.golan@columbia.edu."}], "Journal": "Current biology : CB", "PubDate": "2019Apr01"}, {"PMID": "30894333", "Title": "The spatiotemporal neural dynamics underlying perceived similarity for real-world objects.", "Abstract": "The degree to which we perceive real-world objects as similar or dissimilar structures our perception and guides categorization behavior. Here, we investigated the neural representations enabling perceived similarity using behavioral judgments, fMRI and MEG. As different object dimensions co-occur and partly correlate, to understand the relationship between perceived similarity and brain activity it is necessary to assess the unique role of multiple object dimensions. We thus behaviorally assessed perceived object similarity in relation to shape, function, color and background. We then used representational similarity analyses to relate these behavioral judgments to brain activity. We observed a link between each object dimension and representations in visual cortex. These representations emerged rapidly within 200\u202fms of stimulus onset. Assessing the unique role of each object dimension revealed partly overlapping and distributed representations: while color-related representations distinctly preceded shape-related representations both in the processing hierarchy of the ventral visual pathway and in time, several dimensions were linked to high-level ventral visual cortex. Further analysis singled out the shape dimension as neither fully accounted for by supra-category membership, nor a deep neural network trained on object categorization. Together our results comprehensively characterize the relationship between perceived similarity of key object dimensions and neural activity.", "Keywords": ["MEG", "Object recognition", "Perceived similarity", "Visual perception", "fMRI"], "MeSH terms": ["Adult", "Brain Mapping", "Female", "Humans", "Male", "Pattern Recognition, Visual", "Visual Cortex"], "Authors": [{"First Name": "Radoslaw M", "Last Name": "Cichy", "Affiliation": "Department of Education and Psychology, Freie Universit\u00e4t Berlin, Berlin, Germany; Bernstein Center for Computational Neuroscience Berlin, Berlin, Germany; Berlin School of Mind and Brain, Berlin, Germany. Electronic address: rmcichy@zedat.fu-berlin.de."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Department of Psychology, Zuckerman Mind Brain Behavior Institute, Columbia University, New York, USA."}, {"First Name": "Kamila M", "Last Name": "Jozwik", "Affiliation": "Department of Education and Psychology, Freie Universit\u00e4t Berlin, Berlin, Germany."}, {"First Name": "Jasper J F", "Last Name": "van den Bosch", "Affiliation": "MRC Cognition and Brain Sciences Unit, University of Cambridge, Cambridge, UK."}, {"First Name": "Ian", "Last Name": "Charest", "Affiliation": "MRC Cognition and Brain Sciences Unit, University of Cambridge, Cambridge, UK; School of Psychology, University of Birmingham, Birmingham, UK."}], "Journal": "NeuroImage", "PubDate": "2019Jul01"}, {"PMID": "30837463", "Title": "Distinct representations of basic taste qualities in human gustatory cortex.", "Abstract": "The mammalian tongue contains gustatory receptors tuned to basic taste types, providing an evolutionarily old hedonic compass for what and what not to ingest. Although representation of these distinct taste types is a defining feature of primary gustatory cortex in other animals, their identification has remained elusive in humans, leaving the demarcation of human gustatory cortex unclear. Here we used distributed multivoxel activity patterns to identify regions with patterns of activity differentially sensitive to sweet, salty, bitter, and sour taste qualities. These were found in the insula and overlying operculum, with regions in the anterior and middle insula discriminating all tastes and representing their combinatorial coding. These findings replicated at super-high 7\u2009T field strength using different compounds of sweet and bitter taste types, suggesting taste sensation specificity rather than chemical or receptor specificity. Our results provide evidence of the human gustatory cortex in the insula.", "Keywords": [], "MeSH terms": ["Adult", "Brain Mapping", "Cerebral Cortex", "Female", "Humans", "Magnetic Resonance Imaging", "Male", "Taste", "Taste Buds", "Taste Perception", "Young Adult"], "Authors": [{"First Name": "Junichi", "Last Name": "Chikazoe", "Affiliation": "Section of Brain Function Information, Supportive Center for Brain Research, National Institute for Physiological Sciences, Aichi, 4448585, Japan. j.chikazoe@gmail.com."}, {"First Name": "Daniel H", "Last Name": "Lee", "Affiliation": "Integrative Physiology, University of Colorado, Boulder, Colorado, 80309, USA."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Department of Psychology, Columbia University, New York, New York, 10027, USA."}, {"First Name": "Adam K", "Last Name": "Anderson", "Affiliation": "Department of Human Development, Cornell University, Ithaca, New York, 14850, USA. aka47@cornell.edu."}], "Journal": "Nature communications", "PubDate": "2019Mar05"}, {"PMID": "30250446", "Title": "Corrigendum: Recurrent Convolutional Neural Networks: A Better Model of Biological Object Recognition.", "Abstract": "[This corrects the article DOI: 10.3389/fpsyg.2017.01551.].", "Keywords": ["convolutional neural network", "object recognition", "occlusion", "recurrent neural network", "top-down processing"], "MeSH terms": [], "Authors": [{"First Name": "Courtney J", "Last Name": "Spoerer", "Affiliation": "Medical Research Council Cognition and Brain Sciences Unit, University of Cambridge, Cambridge, United Kingdom."}, {"First Name": "Patrick", "Last Name": "McClure", "Affiliation": "Medical Research Council Cognition and Brain Sciences Unit, University of Cambridge, Cambridge, United Kingdom."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Medical Research Council Cognition and Brain Sciences Unit, University of Cambridge, Cambridge, United Kingdom."}], "Journal": "Frontiers in psychology", "PubDate": "2018"}, {"PMID": "30170148", "Title": "GLMdenoise improves multivariate pattern analysis of fMRI data.", "Abstract": "GLMdenoise is a denoising technique for task-based fMRI. In GLMdenoise, estimates of spatially correlated noise (which may be physiological, instrumental, motion-related, or neural in origin) are derived from the data and incorporated as nuisance regressors in a general linear model (GLM) analysis. We previously showed that GLMdenoise outperforms a variety of other denoising techniques in terms of cross-validation accuracy of GLM estimates (Kay et\u00a0al., 2013a). However, the practical impact of denoising for experimental studies remains unclear. Here we examine whether and to what extent GLMdenoise improves sensitivity in the context of multivariate pattern analysis of fMRI data. On a large number of participants (31 participants across 4 experiments; 3\u202fT, gradient-echo, spatial resolution 2-3.75\u202fmm, temporal resolution 1.3-2\u202fs, number of conditions 32-75), we perform representational similarity analysis (Kriegeskorte et\u00a0al., 2008a) as well as pattern classification (Haxby et\u00a0al., 2001). We find that GLMdenoise substantially improves replicability of representational dissimilarity matrices (RDMs) across independent splits of each participant's dataset (average RDM replicability increases from r\u202f=\u202f0.46 to r\u202f=\u202f0.61). Additionally, we find that GLMdenoise substantially improves pairwise classification accuracy (average classification accuracy increases from 79% correct to 84% correct). We show that GLMdenoise often improves and never degrades performance for individual participants and that GLMdenoise also improves across-participant consistency. We conclude that GLMdenoise is a useful tool that can be routinely used to maximize the amount of information extracted from fMRI activity patterns.", "Keywords": ["BOLD fMRI", "Classification", "Correlated noise", "Cross-validation", "Decoding", "Denoising", "General linear model", "Multivariate pattern analysis", "Representational similarity analysis"], "MeSH terms": ["Adult", "Cerebral Cortex", "Functional Neuroimaging", "Humans", "Image Interpretation, Computer-Assisted", "Image Processing, Computer-Assisted", "Magnetic Resonance Imaging", "Multivariate Analysis", "Pattern Recognition, Automated", "Psychomotor Performance", "Visual Perception"], "Authors": [{"First Name": "Ian", "Last Name": "Charest", "Affiliation": "School of Psychology, University of Birmingham, UK; Medical Research Council Cognition and Brain Sciences Unit, University of Cambridge, UK. Electronic address: i.charest@bham.ac.uk."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Medical Research Council Cognition and Brain Sciences Unit, University of Cambridge, UK; Department of Psychology, Zuckerman Mind Brain Behavior Institute, Columbia University, USA."}, {"First Name": "Kendrick N", "Last Name": "Kay", "Affiliation": "Center for Magnetic Resonance Research (CMRR), Department of Radiology, University of Minnesota, USA."}], "Journal": "NeuroImage", "PubDate": "2018Dec"}, {"PMID": "30127428", "Title": "Cognitive computational neuroscience.", "Abstract": "To learn how cognition is implemented in the brain, we must build computational models that can perform cognitive tasks, and test such models with brain and behavioral experiments. Cognitive science has developed computational models that decompose cognition into functional components. Computational neuroscience has modeled how interacting neurons can implement elementary components of cognition. It is time to assemble the pieces of the puzzle of brain computation and to better integrate these separate disciplines. Modern technologies enable us to measure and manipulate brain activity in unprecedentedly rich ways in animals and humans. However, experiments will yield theoretical insight only when employed to test brain-computational models. Here we review recent work in the intersection of cognitive science, computational neuroscience and artificial intelligence. Computational models that mimic brain information processing during perceptual, cognitive and control tasks are beginning to be developed and tested with brain and behavioral data.", "Keywords": [], "MeSH terms": ["Animals", "Cognition", "Computational Biology", "Computer Simulation", "Humans", "Models, Neurological", "Neurosciences"], "Authors": [{"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Department of Psychology, Department of Neuroscience, Department of Electrical Engineering, Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY, USA. n.kriegeskorte@columbia.edu."}, {"First Name": "Pamela K", "Last Name": "Douglas", "Affiliation": "Center for Cognitive Neuroscience, University of California, Los Angeles, Los Angeles, CA, USA."}], "Journal": "Nature neuroscience", "PubDate": "2018Sep"}, {"PMID": "30111872", "Title": "Author Correction: Retrieval induces adaptive forgetting of competing memories via cortical pattern suppression.", "Abstract": "In the published version of this article, a detail is missing from the Methods section \"Experimental procedure.\" The following sentence is to be inserted at the end of its fourth paragraph: \"If participants failed to respond within 3.5 s, we assumed that they were unable to successfully recognize the item and coded the corresponding trial as an error.\" The critical behavioral forgetting effect is significant irrespective of whether these timeouts are coded as errors (t23 = 4.91, P < 0.001) or as missing data (t23 = 3.31, P < 0.01). The original article has not been corrected.", "Keywords": [], "MeSH terms": [], "Authors": [{"First Name": "Maria", "Last Name": "Wimber", "Affiliation": "School of Psychology, University of Birmingham, Birmingham, UK. m.wimber@bham.ac.uk."}, {"First Name": "Arjen", "Last Name": "Alink", "Affiliation": "MRC Cognition and Brain Sciences Unit, Cambridge, UK."}, {"First Name": "Ian", "Last Name": "Charest", "Affiliation": "MRC Cognition and Brain Sciences Unit, Cambridge, UK."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "MRC Cognition and Brain Sciences Unit, Cambridge, UK."}, {"First Name": "Michael C", "Last Name": "Anderson", "Affiliation": "MRC Cognition and Brain Sciences Unit, Cambridge, UK."}], "Journal": "Nature neuroscience", "PubDate": "2018Oct"}, {"PMID": "29885014", "Title": "Prospective motion correction improves the sensitivity of fMRI pattern decoding.", "Abstract": "We evaluated the effectiveness of prospective motion correction (PMC) on a simple visual task when no deliberate subject motion was present. The PMC system utilizes an in-bore optical camera to track an external marker attached to the participant via a custom-molded mouthpiece. The study was conducted at two resolutions (1.5\u00a0mm vs 3\u00a0mm) and under three conditions (PMC On and Mouthpiece On vs PMC Off and Mouthpiece On vs PMC Off and Mouthpiece Off). Multiple data analysis methods were conducted, including univariate and multivariate approaches, and we demonstrated that the benefit of PMC is most apparent for multi-voxel pattern decoding at higher resolutions. Additional testing on two participants showed that our inexpensive, commercially available mouthpiece solution produced comparable results to a dentist-molded mouthpiece. Our results showed that PMC is increasingly important at higher resolutions for analyses that require accurate voxel registration across time.", "Keywords": ["fMRI analysis", "linear discriminant contrast", "pattern decoding", "prospective motion correction"], "MeSH terms": ["Adult", "Artifacts", "Functional Neuroimaging", "Head Movements", "Humans", "Image Processing, Computer-Assisted", "Magnetic Resonance Imaging", "Pattern Recognition, Automated", "Pattern Recognition, Visual", "Sensitivity and Specificity", "Support Vector Machine", "Visual Cortex"], "Authors": [{"First Name": "Pei", "Last Name": "Huang", "Affiliation": "MRC Cognition and Brain Sciences Unit, University of Cambridge, Cambridge, United Kingdom."}, {"First Name": "Johan D", "Last Name": "Carlin", "Affiliation": "MRC Cognition and Brain Sciences Unit, University of Cambridge, Cambridge, United Kingdom."}, {"First Name": "Arjen", "Last Name": "Alink", "Affiliation": "University Medical Center Hamburg-Eppendorf, Hamburg, DE, Germany."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Columbia University, Zuckerman Mind Brain Behvaior Institute, New York City, New York."}, {"First Name": "Richard N", "Last Name": "Henson", "Affiliation": "MRC Cognition and Brain Sciences Unit, University of Cambridge, Cambridge, United Kingdom."}, {"First Name": "Marta M", "Last Name": "Correia", "Affiliation": "MRC Cognition and Brain Sciences Unit, University of Cambridge, Cambridge, United Kingdom."}], "Journal": "Human brain mapping", "PubDate": "2018Oct"}, {"PMID": "29500078", "Title": "Cognitive Computational Neuroscience: A New Conference for an Emerging Discipline.", "Abstract": "Understanding the computational principles that underlie complex behavior is a central goal in cognitive science, artificial intelligence, and neuroscience. In an attempt to unify these disconnected communities, we created a new conference called Cognitive Computational Neuroscience (CCN). The inaugural meeting revealed considerable enthusiasm but significant obstacles remain.", "Keywords": ["artificial intelligence", "cognitive science", "computational modeling", "machine learning", "neural networks"], "MeSH terms": ["Artificial Intelligence", "Cognitive Neuroscience", "Computational Biology", "Congresses as Topic", "Humans"], "Authors": [{"First Name": "Thomas", "Last Name": "Naselaris", "Affiliation": "Department of Neuroscience, Medical University of South Carolina, Charleston, SC, USA."}, {"First Name": "Danielle S", "Last Name": "Bassett", "Affiliation": "Departments of Bioengineering, Electrical and Systems Engineering, and Neurology, University of Pennsylvania, Philadelphia, PA, USA."}, {"First Name": "Alyson K", "Last Name": "Fletcher", "Affiliation": "Departments of Computer Science, Statistics, and Mathematics, University of California, Los Angeles, Los Angeles, CA, USA."}, {"First Name": "Konrad", "Last Name": "Kording", "Affiliation": "Departments of Bioengineering and Neuroscience, University of Pennsylvania, Philadelphia, PA, USA."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Department of Psychology and Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY, USA."}, {"First Name": "Hendrikje", "Last Name": "Nienborg", "Affiliation": "Werner Reichardt Center for Integrative Neuroscience, University of T\u00fcbingen, T\u00fcbingen, Germany."}, {"First Name": "Russell A", "Last Name": "Poldrack", "Affiliation": "Department of Psychology, Stanford University, Stanford, CA, USA."}, {"First Name": "Daphna", "Last Name": "Shohamy", "Affiliation": "Department of Psychology and Zuckerman Mind Brain Behavior Institute, Columbia University, New York, NY, USA."}, {"First Name": "Kendrick", "Last Name": "Kay", "Affiliation": "Department of Radiology, University of Minnesota, Minneapolis, MN, USA. Electronic address: kay@umn.edu."}], "Journal": "Trends in cognitive sciences", "PubDate": "2018May"}, {"PMID": "29342705", "Title": "Building machines that adapt and compute like brains.", "Abstract": "Building machines that learn and think like humans is essential not only for cognitive science, but also for computational neuroscience, whose ultimate goal is to understand how cognition is implemented in biological brains. A new cognitive computational neuroscience should build cognitive-level and neural-level models, understand their relationships, and test both types of models with both brain and behavioral data.", "Keywords": [], "MeSH terms": ["Brain", "Cognition", "Cognitive Science", "Humans", "Neurosciences", "Thinking"], "Authors": [{"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Medical Research Council Cognition and Brain Sciences Unit,Cambridge,CB2 7EF,United Kingdom.Nikolaus.Kriegeskorte@mrc-cbu.cam.ac.ukRobert.Mok@mrc-cbu.cam.ac.uk."}, {"First Name": "Robert M", "Last Name": "Mok", "Affiliation": "Medical Research Council Cognition and Brain Sciences Unit,Cambridge,CB2 7EF,United Kingdom.Nikolaus.Kriegeskorte@mrc-cbu.cam.ac.ukRobert.Mok@mrc-cbu.cam.ac.uk."}], "Journal": "The Behavioral and brain sciences", "PubDate": "2017Jan"}, {"PMID": "29062291", "Title": "Deep Convolutional Neural Networks Outperform Feature-Based But Not Categorical Models in Explaining Object Similarity Judgments.", "Abstract": "Recent advances in Deep convolutional Neural Networks (DNNs) have enabled unprecedentedly accurate computational models of brain representations, and present an exciting opportunity to model diverse cognitive functions. State-of-the-art DNNs achieve human-level performance on object categorisation, but it is unclear how well they capture human behavior on complex cognitive tasks. Recent reports suggest that DNNs can explain significant variance in one such task, judging object similarity. Here, we extend these findings by replicating them for a rich set of object images, comparing performance across layers within two DNNs of different depths, and examining how the DNNs' performance compares to that of non-computational \"conceptual\" models. Human observers performed similarity judgments for a set of 92 images of real-world objects. Representations of the same images were obtained in each of the layers of two DNNs of different depths (8-layer AlexNet and 16-layer VGG-16). To create conceptual models, other human observers generated visual-feature labels (e.g., \"eye\") and category labels (e.g., \"animal\") for the same image set. Feature labels were divided into parts, colors, textures and contours, while category labels were divided into subordinate, basic, and superordinate categories. We fitted models derived from the features, categories, and from each layer of each DNN to the similarity judgments, using representational similarity analysis to evaluate model performance. In both DNNs, similarity within the last layer explains most of the explainable variance in human similarity judgments. The last layer outperforms almost all feature-based models. Late and mid-level layers outperform some but not all feature-based models. Importantly, categorical models predict similarity judgments significantly better than any DNN layer. Our results provide further evidence for commonalities between DNNs and brain representations. Models derived from visual features other than object parts perform relatively poorly, perhaps because DNNs more comprehensively capture the colors, textures and contours which matter to human object perception. However, categorical models outperform DNNs, suggesting that further work may be needed to bring high-level semantic representations in DNNs closer to those extracted by humans. Modern DNNs explain similarity judgments remarkably well considering they were not trained on this task, and are promising models for many aspects of human cognition.", "Keywords": ["categories", "deep neural networks", "features", "object recognition", "representational similarity analysis", "similarity judgments", "weighted representational modeling"], "MeSH terms": [], "Authors": [{"First Name": "Kamila M", "Last Name": "Jozwik", "Affiliation": "Neural Dynamics of Visual Cognition, Department of Education and Psychology, Free University of Berlin, Berlin, Germany."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Memory and Perception Group, MRC Cognition and Brain Sciences Unit, University of Cambridge, Cambridge, United Kingdom."}, {"First Name": "Katherine R", "Last Name": "Storrs", "Affiliation": "Memory and Perception Group, MRC Cognition and Brain Sciences Unit, University of Cambridge, Cambridge, United Kingdom."}, {"First Name": "Marieke", "Last Name": "Mur", "Affiliation": "Memory and Perception Group, MRC Cognition and Brain Sciences Unit, University of Cambridge, Cambridge, United Kingdom."}], "Journal": "Frontiers in psychology", "PubDate": "2017"}, {"PMID": "28955272", "Title": "Recurrent Convolutional Neural Networks: A Better Model of Biological Object Recognition.", "Abstract": "Feedforward neural networks provide the dominant model of how the brain performs visual object recognition. However, these networks lack the lateral and feedback connections, and the resulting recurrent neuronal dynamics, of the ventral visual pathway in the human and non-human primate brain. Here we investigate recurrent convolutional neural networks with bottom-up (B), lateral (L), and top-down (T) connections. Combining these types of connections yields four architectures (B, BT, BL, and BLT), which we systematically test and compare. We hypothesized that recurrent dynamics might improve recognition performance in the challenging scenario of partial occlusion. We introduce two novel occluded object recognition tasks to test the efficacy of the models, digit clutter (where multiple target digits occlude one another) and digit debris (where target digits are occluded by digit fragments). We find that recurrent neural networks outperform feedforward control models (approximately matched in parametric complexity) at recognizing objects, both in the absence of occlusion and in all occlusion conditions. Recurrent networks were also found to be more robust to the inclusion of additive Gaussian noise. Recurrent neural networks are better in two respects: (1) they are more neurobiologically realistic than their feedforward counterparts; (2) they are better in terms of their ability to recognize objects, especially under challenging conditions. This work shows that computer vision can benefit from using recurrent convolutional architectures and suggests that the ubiquitous recurrent connections in biological brains are essential for task performance.", "Keywords": ["convolutional neural network", "object recognition", "occlusion", "recurrent neural network", "top-down processing"], "MeSH terms": [], "Authors": [{"First Name": "Courtney J", "Last Name": "Spoerer", "Affiliation": "Medical Research Council Cognition and Brain Sciences Unit, University of CambridgeCambridge, United Kingdom."}, {"First Name": "Patrick", "Last Name": "McClure", "Affiliation": "Medical Research Council Cognition and Brain Sciences Unit, University of CambridgeCambridge, United Kingdom."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Medical Research Council Cognition and Brain Sciences Unit, University of CambridgeCambridge, United Kingdom."}], "Journal": "Frontiers in psychology", "PubDate": "2017"}, {"PMID": "28769042", "Title": "Local opposite orientation preferences in V1: fMRI sensitivity to fine-grained pattern information.", "Abstract": "The orientation of a visual grating can be decoded from human primary visual cortex (V1) using functional magnetic resonance imaging (fMRI) at conventional resolutions (2-3 mm voxel width, 3T scanner). It is unclear to what extent this information originates from different spatial scales of neuronal selectivity, ranging from orientation columns to global areal maps. According to the global-areal-map account, fMRI orientation decoding relies exclusively on fMRI voxels in V1 exhibiting a radial or vertical preference. Here we show, by contrast, that 2-mm isotropic voxels in a small patch of V1 within a quarterfield representation exhibit reliable opposite selectivities. Sets of voxels with opposite selectivities are locally intermingled and each set can support orientation decoding. This indicates that global areal maps cannot fully account for orientation information in fMRI and demonstrates that fMRI also reflects fine-grained patterns of neuronal selectivity.", "Keywords": [], "MeSH terms": [], "Authors": [{"First Name": "Arjen", "Last Name": "Alink", "Affiliation": "MRC Cognition and Brain Sciences Unit, Cambridge, UK. a.alink@uke.de."}, {"First Name": "Alexander", "Last Name": "Walther", "Affiliation": "MRC Cognition and Brain Sciences Unit, Cambridge, UK."}, {"First Name": "Alexandra", "Last Name": "Krugliak", "Affiliation": "University of Birmingham, Birmingham, UK."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "MRC Cognition and Brain Sciences Unit, Cambridge, UK."}], "Journal": "Scientific reports", "PubDate": "2017Aug02"}, {"PMID": "28746335", "Title": "Adjudicating between face-coding models with individual-face fMRI responses.", "Abstract": "The perceptual representation of individual faces is often explained with reference to a norm-based face space. In such spaces, individuals are encoded as vectors where identity is primarily conveyed by direction and distinctiveness by eccentricity. Here we measured human fMRI responses and psychophysical similarity judgments of individual face exemplars, which were generated as realistic 3D animations using a computer-graphics model. We developed and evaluated multiple neurobiologically plausible computational models, each of which predicts a representational distance matrix and a regional-mean activation profile for 24 face stimuli. In the fusiform face area, a face-space coding model with sigmoidal ramp tuning provided a better account of the data than one based on exemplar tuning. However, an image-processing model with weighted banks of Gabor filters performed similarly. Accounting for the data required the inclusion of a measurement-level population averaging mechanism that approximates how fMRI voxels locally average distinct neuronal tunings. Our study demonstrates the importance of comparing multiple models and of modeling the measurement process in computational neuroimaging.", "Keywords": [], "MeSH terms": ["Algorithms", "Brain", "Brain Mapping", "Face", "Facial Recognition", "Humans", "Magnetic Resonance Imaging", "Models, Neurological", "Principal Component Analysis"], "Authors": [{"First Name": "Johan D", "Last Name": "Carlin", "Affiliation": "MRC Cognition and Brain Sciences Unit, University of Cambridge, Cambridge, United Kingdom."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "MRC Cognition and Brain Sciences Unit, University of Cambridge, Cambridge, United Kingdom."}], "Journal": "PLoS computational biology", "PubDate": "2017Jul"}, {"PMID": "28437426", "Title": "Representational models: A common framework for understanding encoding, pattern-component, and representational-similarity analysis.", "Abstract": "Representational models specify how activity patterns in populations of neurons (or, more generally, in multivariate brain-activity measurements) relate to sensory stimuli, motor responses, or cognitive processes. In an experimental context, representational models can be defined as hypotheses about the distribution of activity profiles across experimental conditions. Currently, three different methods are being used to test such hypotheses: encoding analysis, pattern component modeling (PCM), and representational similarity analysis (RSA). Here we develop a common mathematical framework for understanding the relationship of these three methods, which share one core commonality: all three evaluate the second moment of the distribution of activity profiles, which determines the representational geometry, and thus how well any feature can be decoded from population activity. Using simulated data for three different experimental designs, we compare the power of the methods to adjudicate between competing representational models. PCM implements a likelihood-ratio test and therefore provides the most powerful test if its assumptions hold. However, the other two approaches-when conducted appropriately-can perform similarly. In encoding analysis, the linear model needs to be appropriately regularized, which effectively imposes a prior on the activity profiles. With such a prior, an encoding model specifies a well-defined distribution of activity profiles. In RSA, the unequal variances and statistical dependencies of the dissimilarity estimates need to be taken into account to reach near-optimal power in inference. The three methods render different aspects of the information explicit (e.g. single-response tuning in encoding analysis and population-response representational dissimilarity in RSA) and have specific advantages in terms of computational demands, ease of use, and extensibility. The three methods are properly construed as complementary components of a single data-analytical toolkit for understanding neural representations on the basis of multivariate brain-activity data.", "Keywords": [], "MeSH terms": ["Algorithms", "Brain", "Computational Biology", "Linear Models", "Magnetic Resonance Imaging", "Models, Neurological", "Neurons"], "Authors": [{"First Name": "J\u00f6rn", "Last Name": "Diedrichsen", "Affiliation": "Brain and Mind Institute, Department for Computer Science, Department for Statistical and Actuarial Science, Western University, London, Canada."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Cognitive and Brain Sciences Unit, Cambridge University, Cambridge, United Kingdom."}], "Journal": "PLoS computational biology", "PubDate": "2017Apr"}, {"PMID": "28298702", "Title": "Fixed versus mixed RSA:\u00a0Explaining visual representations by fixed and mixed feature sets from shallow and deep computational models.", "Abstract": "Studies of the primate visual system have begun to test a wide range of complex computational object-vision models. Realistic models have many parameters, which in practice cannot be fitted using the limited amounts of brain-activity data typically available. Task performance optimization (e.g. using backpropagation to train neural networks) provides major constraints for fitting parameters and discovering nonlinear representational features appropriate for the task (e.g. object classification). Model representations can be compared to brain representations in terms of the representational dissimilarities they predict for an image set. This method, called representational similarity analysis (RSA), enables us to test the representational feature space as is (fixed RSA) or to fit a linear transformation that mixes the nonlinear model features so as to best explain a cortical area's representational space (mixed RSA). Like voxel/population-receptive-field modelling, mixed RSA uses a training set (different stimuli) to fit one weight per model feature and response channel (voxels here), so as to best predict the response profile across images for each response channel. We analysed response patterns elicited by natural images, which were measured with functional magnetic resonance imaging (fMRI). We found that early visual areas were best accounted for by shallow models, such as a Gabor wavelet pyramid (GWP). The GWP model performed similarly with and without mixing, suggesting that the original features already approximated the representational space, obviating the need for mixing. However, a higher ventral-stream visual representation (lateral occipital region) was best explained by the higher layers of a deep convolutional network and mixing of its feature set was essential for this model to explain the representation. We suspect that mixing was essential because the convolutional network had been trained to discriminate a set of 1000 categories, whose frequencies in the training set did not match their frequencies in natural experience or their behavioural importance. The latter factors might determine the representational prominence of semantic dimensions in higher-level ventral-stream areas. Our results demonstrate the benefits of testing both the specific representational hypothesis expressed by a model's original feature space and the hypothesis space generated by linear transformations of that feature space.", "Keywords": ["Deep convolutional networks", "Mixed RSA", "Object-vision models", "Representational similarity analysis", "Voxel-receptive-field modelling"], "MeSH terms": [], "Authors": [{"First Name": "Seyed-Mahdi", "Last Name": "Khaligh-Razavi", "Affiliation": "MRC Cognition and Brain Sciences Unit, Cambridge, UK; Computer Science & Artificial intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA."}, {"First Name": "Linda", "Last Name": "Henriksson", "Affiliation": "MRC Cognition and Brain Sciences Unit, Cambridge, UK; Department of Neuroscience and Biomedical Engineering, Aalto University, Espoo, Finland."}, {"First Name": "Kendrick", "Last Name": "Kay", "Affiliation": "Department of Psychology, Washington University in St. Louis, St. Louis, MO, USA."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "MRC Cognition and Brain Sciences Unit, Cambridge, UK."}], "Journal": "Journal of mathematical psychology", "PubDate": "2017Feb"}, {"PMID": "28230846", "Title": "Best practices in data analysis and sharing in neuroimaging using MRI.", "Abstract": "Given concerns about the reproducibility of scientific findings, neuroimaging must define best practices for data analysis, results reporting, and algorithm and data sharing to promote transparency, reliability and collaboration. We describe insights from developing a set of recommendations on behalf of the Organization for Human Brain Mapping and identify barriers that impede these practices, including how the discipline must change to fully exploit the potential of the world's neuroimaging data.", "Keywords": [], "MeSH terms": ["Brain Mapping", "Databases, Factual", "Humans", "Information Dissemination", "Magnetic Resonance Imaging", "Neuroimaging", "Reproducibility of Results"], "Authors": [{"First Name": "Thomas E", "Last Name": "Nichols", "Affiliation": "University of Warwick, Coventry, UK."}, {"First Name": "Samir", "Last Name": "Das", "Affiliation": "McGill University, Montreal, Canada."}, {"First Name": "Simon B", "Last Name": "Eickhoff", "Affiliation": "Institute of Neuroscience and Medicine (INM-1), J\u00fclich Research Center, J\u00fclich, Germany."}, {"First Name": "Alan C", "Last Name": "Evans", "Affiliation": "McGill University, Montreal, Canada."}, {"First Name": "Tristan", "Last Name": "Glatard", "Affiliation": "McGill University, Montreal, Canada."}, {"First Name": "Michael", "Last Name": "Hanke", "Affiliation": "Otto-von-Guericke-University, Magdeburg, Germany."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "MRC Cognition and Brain Sciences Unit, Cambridge, UK."}, {"First Name": "Michael P", "Last Name": "Milham", "Affiliation": "Child Mind Institute, New York, New York, USA."}, {"First Name": "Russell A", "Last Name": "Poldrack", "Affiliation": "Stanford University, Stanford, California, USA."}, {"First Name": "Jean-Baptiste", "Last Name": "Poline", "Affiliation": "University of California, Berkeley, California, USA."}, {"First Name": "Erika", "Last Name": "Proal", "Affiliation": "NEUROingenia Clinical and Research Center, Mexico City, Mexico."}, {"First Name": "Bertrand", "Last Name": "Thirion", "Affiliation": "Inria, Paris-Saclay University, Paris, France."}, {"First Name": "David C", "Last Name": "Van Essen", "Affiliation": "Washington University in St. Louis, St. Louis, Missouri, USA."}, {"First Name": "Tonya", "Last Name": "White", "Affiliation": "Erasmus University Medical Center, Rotterdam, The Netherlands."}, {"First Name": "B T Thomas", "Last Name": "Yeo", "Affiliation": "National University of Singapore, Singapore."}], "Journal": "Nature neuroscience", "PubDate": "2017Feb23"}, {"PMID": "28082889", "Title": "Representational Distance Learning for Deep Neural Networks.", "Abstract": "Deep neural networks (DNNs) provide useful models of visual representational transformations. We present a method that enables a DNN (student) to learn from the internal representational spaces of a reference model (teacher), which could be another DNN or, in the future, a biological brain. Representational spaces of the student and the teacher are characterized by representational distance matrices (RDMs). We propose representational distance learning (RDL), a stochastic gradient descent method that drives the RDMs of the student to approximate the RDMs of the teacher. We demonstrate that RDL is competitive with other transfer learning techniques for two publicly available benchmark computer vision datasets (MNIST and CIFAR-100), while allowing for architectural differences between student and teacher. By pulling the student's RDMs toward those of the teacher, RDL significantly improved visual classification performance when compared to baseline networks that did not use transfer learning. In the future, RDL may enable combined supervised training of deep neural networks using task constraints (e.g., images and category labels) and constraints from brain-activity measurements, so as to build models that replicate the internal representational spaces of biological brains.", "Keywords": ["computational neuroscience", "distance matrices", "neural networks", "transfer learning", "visual perception"], "MeSH terms": [], "Authors": [{"First Name": "Patrick", "Last Name": "McClure", "Affiliation": "MRC Cognition and Brain Sciences Unit Cambridge, UK."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "MRC Cognition and Brain Sciences Unit Cambridge, UK."}], "Journal": "Frontiers in computational neuroscience", "PubDate": "2016"}, {"PMID": "28077514", "Title": "Representational Similarity Mapping of Distributional Semantics in Left Inferior Frontal, Middle Temporal, and Motor Cortex.", "Abstract": "Language comprehension engages a distributed network of frontotemporal, parietal, and sensorimotor regions, but it is still unclear how meaning of words and their semantic relationships are represented and processed within these regions and to which degrees lexico-semantic representations differ between regions and semantic types. We used fMRI and representational similarity analysis to relate word-elicited multivoxel patterns to semantic similarity between action and object words. In left inferior frontal (BA 44-45-47), left posterior middle temporal and left precentral cortex, the similarity of brain response patterns reflected semantic similarity among action-related verbs, as well as across lexical classes-between action verbs and tool-related nouns and, to a degree, between action verbs and food nouns, but not between action verbs and animal nouns. Instead, posterior inferior temporal cortex exhibited a reverse response pattern, which reflected the semantic similarity among object-related nouns, but not action-related words. These results show that semantic similarity is encoded by a range of cortical areas, including multimodal association (e.g., anterior inferior frontal, posterior middle temporal) and modality-preferential (premotor) cortex and that the representational geometries in these regions are partly dependent on semantic type, with semantic similarity among action-related words crossing lexical-semantic category boundaries.", "Keywords": ["corpus co-occurrence", "fMRI", "language comprehension", "representational similarity analysis", "semantic word category"], "MeSH terms": ["Adult", "Brain Mapping", "Cerebral Cortex", "Comprehension", "Female", "Humans", "Language", "Magnetic Resonance Imaging", "Male", "Semantics", "Speech Perception"], "Authors": [{"First Name": "Francesca", "Last Name": "Carota", "Affiliation": "MRC Cognition and Brain Sciences Unit, 15 Chaucer Road, Cambridge CB2 7EF, UK."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "MRC Cognition and Brain Sciences Unit, 15 Chaucer Road, Cambridge CB2 7EF, UK."}, {"First Name": "Hamed", "Last Name": "Nili", "Affiliation": "MRC Cognition and Brain Sciences Unit, 15 Chaucer Road, Cambridge CB2 7EF, UK."}, {"First Name": "Friedemann", "Last Name": "Pulverm\u00fcller", "Affiliation": "MRC Cognition and Brain Sciences Unit, 15 Chaucer Road, Cambridge CB2 7EF, UK."}], "Journal": "Cerebral cortex (New York, N.Y. : 1991)", "PubDate": "2017Jan01"}, {"PMID": "27764662", "Title": "Grid Cells for Conceptual Spaces?", "Abstract": "\"Grid cells\" encode an animal's location and direction of movement in 2D physical environments via regularly repeating receptive fields. Constantinescu et\u00a0al. (2016) report the first evidence of grid cells for 2D conceptual spaces. The work has exciting implications for mental representation and shows how detailed neural-coding hypotheses can be tested with bulk population-activity measures.", "Keywords": [], "MeSH terms": ["Animals", "Grid Cells", "Movement", "Neurons", "Orientation"], "Authors": [{"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Medical Research Council Cognition and Brain Sciences Unit, 15 Chaucer Road, Cambridge CB2 7EF, UK. Electronic address: nikolaus.kriegeskorte@mrc-cbu.cam.ac.uk."}, {"First Name": "Katherine R", "Last Name": "Storrs", "Affiliation": "Medical Research Council Cognition and Brain Sciences Unit, 15 Chaucer Road, Cambridge CB2 7EF, UK. Electronic address: katherine.storrs@mrc-cbu.cam.ac.uk."}], "Journal": "Neuron", "PubDate": "2016Oct19"}, {"PMID": "27605606", "Title": "Perception and Processing of Faces in the Human Brain Is Tuned to Typical Feature Locations.", "Abstract": "Faces are salient social stimuli whose features attract a stereotypical pattern of fixations. The implications of this gaze behavior for perception and brain activity are largely unknown. Here, we characterize and quantify a retinotopic bias implied by typical gaze behavior toward faces, which leads to eyes and mouth appearing most often in the upper and lower visual field, respectively. We found that the adult human visual system is tuned to these contingencies. In two recognition experiments, recognition performance for isolated face parts was better when they were presented at typical, rather than reversed, visual field locations. The recognition cost of reversed locations was equal to \u223c60% of that for whole face inversion in the same sample. Similarly, an fMRI experiment showed that patterns of activity evoked by eye and mouth stimuli in the right inferior occipital gyrus could be separated with significantly higher accuracy when these features were presented at typical, rather than reversed, visual field locations. Our findings demonstrate that human face perception is determined not only by the local position of features within a face context, but by whether features appear at the typical retinotopic location given normal gaze behavior. Such location sensitivity may reflect fine-tuning of category-specific visual processing to retinal input statistics. Our findings further suggest that retinotopic heterogeneity might play a role for face inversion effects and for the understanding of conditions affecting gaze behavior toward faces, such as autism spectrum disorders and congenital prosopagnosia.", "Keywords": ["decoding", "fMRI", "face perception", "gaze behavior", "occipital face area", "retinotopy"], "MeSH terms": ["Adult", "Attention", "Face", "Female", "Fixation, Ocular", "Humans", "Image Processing, Computer-Assisted", "Magnetic Resonance Imaging", "Male", "Middle Aged", "Occipital Lobe", "Oxygen", "Pattern Recognition, Visual", "Photic Stimulation", "Recognition, Psychology", "Young Adult"], "Authors": [{"First Name": "Benjamin", "Last Name": "de Haas", "Affiliation": "Institute of Cognitive Neuroscience, Wellcome Trust Centre for Neuroimaging, Experimental Psychology, and benjamin.haas.09@ucl.ac.uk."}, {"First Name": "D Samuel", "Last Name": "Schwarzkopf", "Affiliation": "Institute of Cognitive Neuroscience, Experimental Psychology, and."}, {"First Name": "Ivan", "Last Name": "Alvarez", "Affiliation": "Institute of Child Health, University College London, London WC1H 0AP, United Kingdom, Oxford University Centre for Functional MRI of the Brain, Oxford OX3 9DU, United Kingdom."}, {"First Name": "Rebecca P", "Last Name": "Lawson", "Affiliation": "Institute of Cognitive Neuroscience, Wellcome Trust Centre for Neuroimaging."}, {"First Name": "Linda", "Last Name": "Henriksson", "Affiliation": "MRC Cognition and Brain Sciences Unit, Cambridge CB2 7EF, United Kingdom, and Department of Neuroscience and Biomedical Engineering, Aalto University, Espoo FI-00076, Finland."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "MRC Cognition and Brain Sciences Unit, Cambridge CB2 7EF, United Kingdom, and."}, {"First Name": "Geraint", "Last Name": "Rees", "Affiliation": "Institute of Cognitive Neuroscience, Wellcome Trust Centre for Neuroimaging."}], "Journal": "The Journal of neuroscience : the official journal of the Society for Neuroscience", "PubDate": "2016Sep07"}, {"PMID": "27574316", "Title": "Inferring brain-computational mechanisms with models of activity measurements.", "Abstract": "High-resolution functional imaging is providing increasingly rich measurements of brain activity in animals and humans. A major challenge is to leverage such data to gain insight into the brain's computational mechanisms. The first step is to define candidate brain-computational models (BCMs) that can perform the behavioural task in question. We would then like to infer which of the candidate BCMs best accounts for measured brain-activity data. Here we describe a method that complements each BCM by a measurement model (MM), which simulates the way the brain-activity measurements reflect neuronal activity (e.g. local averaging in functional magnetic resonance imaging (fMRI) voxels or sparse sampling in array recordings). The resulting generative model (BCM-MM) produces simulated measurements. To avoid having to fit the MM to predict each individual measurement channel of the brain-activity data, we compare the measured and predicted data at the level of summary statistics. We describe a novel particular implementation of this approach, called probabilistic representational similarity analysis (pRSA) with MMs, which uses representational dissimilarity matrices (RDMs) as the summary statistics. We validate this method by simulations of fMRI measurements (locally averaging voxels) based on a deep convolutional neural network for visual object recognition. Results indicate that the way the measurements sample the activity patterns strongly affects the apparent representational dissimilarities. However, modelling of the measurement process can account for these effects, and different BCMs remain distinguishable even under substantial noise. The pRSA method enables us to perform Bayesian inference on the set of BCMs and to recognize the data-generating model in each case.This article is part of the themed issue 'Interpreting BOLD: a dialogue between cognitive and cellular neuroscience'.", "Keywords": ["brain representation", "brain-activity data", "brain-computational model", "representational similarity analysis", "statistical inference"], "MeSH terms": ["Animals", "Bayes Theorem", "Brain", "Brain Mapping", "Humans", "Magnetic Resonance Imaging", "Models, Neurological", "Visual Perception"], "Authors": [{"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Medical Research Council Cognition and Brain Sciences Unit, Cambridge, UK nikolaus.kriegeskorte@mrc-cbu.cam.ac.uk."}, {"First Name": "J\u00f6rn", "Last Name": "Diedrichsen", "Affiliation": "Brain and Mind Institute, Department of Computer Science and Department of Statistical and Actuarial Sciences, Western University, London, Ontario, Canada."}], "Journal": "Philosophical transactions of the Royal Society of London. Series B, Biological sciences", "PubDate": "2016Oct05"}, {"PMID": "26899210", "Title": "Perceptual similarity of visual patterns predicts dynamic neural activation patterns measured with MEG.", "Abstract": "Perceptual similarity is a cognitive judgment that represents the end-stage of a complex cascade of hierarchical processing throughout visual cortex. Previous studies have shown a correspondence between the similarity of coarse-scale fMRI activation patterns and the perceived similarity of visual stimuli, suggesting that visual objects that appear similar also share similar underlying patterns of neural activation. Here we explore the temporal relationship between the human brain's time-varying representation of visual patterns and behavioral judgments of perceptual similarity. The visual stimuli were abstract patterns constructed from identical perceptual units (oriented Gabor patches) so that each pattern had a unique global form or perceptual 'Gestalt'. The visual stimuli were decodable from evoked neural activation patterns measured with magnetoencephalography (MEG), however, stimuli differed in the similarity of their neural representation as estimated by differences in decodability. Early after stimulus onset (from 50ms), a model based on retinotopic organization predicted the representational similarity of the visual stimuli. Following the peak correlation between the retinotopic model and neural data at 80ms, the neural representations quickly evolved so that retinotopy no longer provided a sufficient account of the brain's time-varying representation of the stimuli. Overall the strongest predictor of the brain's representation was a model based on human judgments of perceptual similarity, which reached the limits of the maximum correlation with the neural data defined by the 'noise ceiling'. Our results show that large-scale brain activation patterns contain a neural signature for the perceptual Gestalt of composite visual features, and demonstrate a strong correspondence between perception and complex patterns of brain activity.", "Keywords": ["Decoding", "Gestalt perception", "Magnetoencephalography (MEG)", "Perceptual similarity", "Representational geometry", "Representational similarity analysis"], "MeSH terms": ["Adult", "Brain", "Female", "Humans", "Judgment", "Magnetoencephalography", "Male", "Pattern Recognition, Visual", "Photic Stimulation", "Young Adult"], "Authors": [{"First Name": "Susan G", "Last Name": "Wardle", "Affiliation": "Department of Cognitive Science and ARC Centre of Excellence in Cognition and Its Disorders and Perception in Action Research Centre, Macquarie University, Sydney, New South Wales 2109, Australia."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Medical Research Council, Cognition and Brain Sciences Unit, Cambridge CB2 7EF, UK."}, {"First Name": "Tijl", "Last Name": "Grootswagers", "Affiliation": "Department of Cognitive Science and ARC Centre of Excellence in Cognition and Its Disorders and Perception in Action Research Centre, Macquarie University, Sydney, New South Wales 2109, Australia."}, {"First Name": "Seyed-Mahdi", "Last Name": "Khaligh-Razavi", "Affiliation": "Medical Research Council, Cognition and Brain Sciences Unit, Cambridge CB2 7EF, UK."}, {"First Name": "Thomas A", "Last Name": "Carlson", "Affiliation": "Department of Cognitive Science and ARC Centre of Excellence in Cognition and Its Disorders and Perception in Action Research Centre, Macquarie University, Sydney, New South Wales 2109, Australia; Department of Psychology, University of Maryland, College Park, MD, USA. Electronic address: thomas.carlson@mq.edu.au."}], "Journal": "NeuroImage", "PubDate": "2016May15"}, {"PMID": "26707889", "Title": "Reliability of dissimilarity measures for multi-voxel pattern analysis.", "Abstract": "Representational similarity analysis of activation patterns has become an increasingly important tool for studying brain representations. The dissimilarity between two patterns is commonly quantified by the correlation distance or the accuracy of a linear classifier. However, there are many different ways to measure pattern dissimilarity and little is known about their relative reliability. Here, we compare the reliability of three classes of dissimilarity measure: classification accuracy, Euclidean/Mahalanobis distance, and Pearson correlation distance. Using simulations and four real functional magnetic resonance imaging (fMRI) datasets, we demonstrate that continuous dissimilarity measures are substantially more reliable than the classification accuracy. The difference in reliability can be explained by two characteristics of classifiers: discretization and susceptibility of the discriminant function to shifts of the pattern ensemble between imaging runs. Reliability can be further improved through multivariate noise normalization for all measures. Finally, unlike conventional distance measures, crossvalidated distances provide unbiased estimates of pattern dissimilarity on a ratio scale, thus providing an interpretable zero point. Overall, our results indicate that the crossvalidated Mahalanobis distance is preferable to both the classification accuracy and the correlation distance for characterizing representational geometries.", "Keywords": ["Classification", "Crossvalidation", "Decoding", "Linear discriminant", "Machine learning", "Multi-voxel pattern analysis", "Noise normalization", "Representational similarity analysis", "fMRI"], "MeSH terms": ["Algorithms", "Brain", "Brain Mapping", "Data Interpretation, Statistical", "Female", "Humans", "Image Enhancement", "Image Interpretation, Computer-Assisted", "Magnetic Resonance Imaging", "Male", "Pattern Recognition, Automated", "Reproducibility of Results", "Sensitivity and Specificity", "Subtraction Technique"], "Authors": [{"First Name": "Alexander", "Last Name": "Walther", "Affiliation": "MRC Cognition and Brain Sciences Unit, 15 Chaucer Road, CB2 7EF, Cambridge, United Kingdom; Institute of Cognitive Neuroscience, University College London, Alexandra House, 17 Queen Square, London WC1N 3AR, United Kingdom. Electronic address: alexander.walther@mrc-cbu.cam.ac.uk."}, {"First Name": "Hamed", "Last Name": "Nili", "Affiliation": "Department of Experimental Psychology, University of Oxford, South Parks Road, OX1 3UD, Oxford, United Kingdom. Electronic address: hamed.nili@psy.ox.ac.uk."}, {"First Name": "Naveed", "Last Name": "Ejaz", "Affiliation": "Institute of Cognitive Neuroscience, University College London, Alexandra House, 17 Queen Square, London WC1N 3AR, United Kingdom. Electronic address: n.ejaz@ucl.ac.uk."}, {"First Name": "Arjen", "Last Name": "Alink", "Affiliation": "MRC Cognition and Brain Sciences Unit, 15 Chaucer Road, CB2 7EF, Cambridge, United Kingdom. Electronic address: arjen.alink@mrc-cbu.cam.ac.uk."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "MRC Cognition and Brain Sciences Unit, 15 Chaucer Road, CB2 7EF, Cambridge, United Kingdom. Electronic address: nikolaus.kriegeskorte@mrc-cbu.cam.ac.uk."}, {"First Name": "J\u00f6rn", "Last Name": "Diedrichsen", "Affiliation": "Institute of Cognitive Neuroscience, University College London, Alexandra House, 17 Queen Square, London WC1N 3AR, United Kingdom. Electronic address: j.diedrichsen@ucl.ac.uk."}], "Journal": "NeuroImage", "PubDate": "2016Aug15"}, {"PMID": "28532370", "Title": "Deep Neural Networks: A New Framework for Modeling Biological Vision and Brain Information Processing.", "Abstract": "Recent advances in neural network modeling have enabled major strides in computer vision and other artificial intelligence applications. Human-level visual recognition abilities are coming within reach of artificial systems. Artificial neural networks are inspired by the brain, and their computations could be implemented in biological neurons. Convolutional feedforward networks, which now dominate computer vision, take further inspiration from the architecture of the primate visual hierarchy. However, the current models are designed with engineering goals, not to model brain computations. Nevertheless, initial studies comparing internal representations between these models and primate brains find surprisingly similar representational spaces. With human-level performance no longer out of reach, we are entering an exciting new era, in which we will be able to build biologically faithful feedforward and recurrent computational models of how biological brains perform high-level feats of intelligence, including vision.", "Keywords": ["artificial intelligence", "biological vision", "computational neuroscience", "computer vision", "deep learning", "neural network", "object recognition"], "MeSH terms": [], "Authors": [{"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Medical Research Council Cognition and Brain Sciences Unit, University of Cambridge, Cambridge CB2 7EF, United Kingdom; email: nikolaus.kriegeskorte@mrc-cbu.cam.ac.uk."}], "Journal": "Annual review of vision science", "PubDate": "2015Nov24"}, {"PMID": "26493748", "Title": "Visual features as stepping stones toward semantics: Explaining object similarity in IT and perception with non-negative least squares.", "Abstract": "Object similarity, in brain representations and conscious perception, must reflect a combination of the visual appearance of the objects on the one hand and the categories the objects belong to on the other. Indeed, visual object features and category membership have each been shown to contribute to the object representation in human inferior temporal (IT) cortex, as well as to object-similarity judgments. However, the explanatory power of features and categories has not been directly compared. Here, we investigate whether the IT object representation and similarity judgments are best explained by a categorical or a feature-based model. We use rich models (>100 dimensions) generated by human observers for a set of 96 real-world object images. The categorical model consists of a hierarchically nested set of category labels (such as \"human\", \"mammal\", and \"animal\"). The feature-based model includes both object parts (such as \"eye\", \"tail\", and \"handle\") and other descriptive features (such as \"circular\", \"green\", and \"stubbly\"). We used non-negative least squares to fit the models to the brain representations (estimated from functional magnetic resonance imaging data) and to similarity judgments. Model performance was estimated on held-out images not used in fitting. Both models explained significant variance in IT and the amounts explained were not significantly different. The combined model did not explain significant additional IT variance, suggesting that it is the shared model variance (features correlated with categories, categories correlated with features) that best explains IT. The similarity judgments were almost fully explained by the categorical model, which explained significantly more variance than the feature-based model. The combined model did not explain significant additional variance in the similarity judgments. Our findings suggest that IT uses features that help to distinguish categories as stepping stones toward a semantic representation. Similarity judgments contain additional categorical variance that is not explained by visual features, reflecting a higher-level more purely semantic representation.", "Keywords": ["Categories", "Features", "Human inferior temporal cortex", "Object vision", "Representational similarity analysis", "fMRI"], "MeSH terms": ["Adult", "Brain", "Brain Mapping", "Concept Formation", "Female", "Humans", "Image Processing, Computer-Assisted", "Judgment", "Least-Squares Analysis", "Magnetic Resonance Imaging", "Male", "Models, Theoretical", "Oxygen", "Pattern Recognition, Visual", "Photic Stimulation", "Semantics"], "Authors": [{"First Name": "Kamila M", "Last Name": "Jozwik", "Affiliation": "Medical Research Council, Cognition and Brain Sciences Unit, 15 Chaucer Road, Cambridge CB2 7EF, United Kingdom. Electronic address: kj287@cam.ac.uk."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Medical Research Council, Cognition and Brain Sciences Unit, 15 Chaucer Road, Cambridge CB2 7EF, United Kingdom. Electronic address: nikolaus.kriegeskorte@mrc-cbu.cam.ac.uk."}, {"First Name": "Marieke", "Last Name": "Mur", "Affiliation": "Medical Research Council, Cognition and Brain Sciences Unit, 15 Chaucer Road, Cambridge CB2 7EF, United Kingdom. Electronic address: marieke.mur@mrc-cbu.cam.ac.uk."}], "Journal": "Neuropsychologia", "PubDate": "2016Mar"}, {"PMID": "26235800", "Title": "Faciotopy-A face-feature map with face-like topology in the human occipital face area.", "Abstract": "The occipital face area (OFA) and fusiform face area (FFA) are brain regions thought to be specialized for face perception. However, their intrinsic functional organization and status as cortical areas with well-defined boundaries remains unclear. Here we test these regions for \"faciotopy\", a particular hypothesis about their intrinsic functional organisation. A faciotopic area would contain a face-feature map on the cortical surface, where cortical patches represent face features and neighbouring patches represent features that are physically neighbouring in a face. The faciotopy hypothesis is motivated by the idea that face regions might develop from a retinotopic protomap and acquire their selectivity for face features through natural visual experience. Faces have a prototypical configuration of features, are usually perceived in a canonical upright orientation, and are frequently fixated in particular locations. To test the faciotopy hypothesis, we presented images of isolated face features at fixation to subjects during functional magnetic resonance imaging. The responses in V1 were best explained by low-level image properties of the stimuli. OFA, and to a lesser degree FFA, showed evidence for faciotopic organization. When a single patch of cortex was estimated for each face feature, the cortical distances between the feature patches reflected the physical distance between the features in a face. Faciotopy would be the first example, to our knowledge, of a cortical map reflecting the topology, not of a part of the organism itself (its retina in retinotopy, its body in somatotopy), but of an external object of particular perceptual significance.", "Keywords": ["FFA", "Face feature", "Face processing", "OFA", "fMRI"], "MeSH terms": ["Adult", "Brain Mapping", "Face", "Female", "Humans", "Magnetic Resonance Imaging", "Male", "Middle Aged", "Occipital Lobe", "Pattern Recognition, Visual", "Photic Stimulation", "Young Adult"], "Authors": [{"First Name": "Linda", "Last Name": "Henriksson", "Affiliation": "MRC Cognition and Brain Sciences Unit, Cambridge, UK; Department of Neuroscience and Biomedical Engineering, Aalto University, Espoo, Finland. Electronic address: linda.henriksson@aalto.fi."}, {"First Name": "Marieke", "Last Name": "Mur", "Affiliation": "MRC Cognition and Brain Sciences Unit, Cambridge, UK."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "MRC Cognition and Brain Sciences Unit, Cambridge, UK. Electronic address: nikolaus.kriegeskorte@mrc-cbu.cam.ac.uk."}], "Journal": "Cortex; a journal devoted to the study of the nervous system and behavior", "PubDate": "2015Nov"}, {"PMID": "26010826", "Title": "Similarity, not complexity, determines visual working memory performance.", "Abstract": "A number of studies have shown that visual working memory (WM) is poorer for complex versus simple items, traditionally accounted for by higher information load placing greater demands on encoding and storage capacity limits. Other research suggests that it may not be complexity that determines WM performance per se, but rather increased perceptual similarity between complex items as a result of a large amount of overlapping information. Increased similarity is thought to lead to greater comparison errors between items encoded into WM and the test item(s) presented at retrieval. However, previous studies have used different object categories to manipulate complexity and similarity, raising questions as to whether these effects are simply due to cross-category differences. For the first time, here the relationship between complexity and similarity in WM using the same stimulus category (abstract polygons) are investigated. The authors used a delayed discrimination task to measure WM for 1-4 complex versus simple simultaneously presented items and manipulated the similarity between the single test item at retrieval and the sample items at encoding. WM was poorer for complex than simple items only when the test item was similar to 1 of the encoding items, and not when it was dissimilar or identical. The results provide clear support for reinterpretation of the complexity effect in WM as a similarity effect and highlight the importance of the retrieval stage in governing WM performance. The authors discuss how these findings can be reconciled with current models of WM capacity limits.", "Keywords": [], "MeSH terms": ["Analysis of Variance", "Attention", "Discrimination, Psychological", "Female", "Humans", "Male", "Memory, Short-Term", "Pattern Recognition, Visual", "Reaction Time", "Young Adult"], "Authors": [{"First Name": "Margaret C", "Last Name": "Jackson", "Affiliation": "School of Psychology, University of Aberdeen."}, {"First Name": "David E J", "Last Name": "Linden", "Affiliation": "School of Psychology, Cardiff University."}, {"First Name": "Mark V", "Last Name": "Roberts", "Affiliation": "School of Psychology, Bangor University."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Cognition and Brain Sciences Unit, University of Cambridge."}, {"First Name": "Corinna", "Last Name": "Haenschel", "Affiliation": "Department of Psychology, City University London."}], "Journal": "Journal of experimental psychology. Learning, memory, and cognition", "PubDate": "2015Nov"}, {"PMID": "25896934", "Title": "Visual representations are dominated by intrinsic fluctuations correlated between areas.", "Abstract": "Intrinsic cortical dynamics are thought to underlie trial-to-trial variability of visually evoked responses in animal models. Understanding their function in the context of sensory processing and representation is a major current challenge. Here we report that intrinsic cortical dynamics strongly affect the representational geometry of a brain region, as reflected in response-pattern dissimilarities, and exaggerate the similarity of representations between brain regions. We characterized the representations in several human visual areas by representational dissimilarity matrices (RDMs) constructed from fMRI response-patterns for natural image stimuli. The RDMs of different visual areas were highly similar when the response-patterns were estimated on the basis of the same trials (sharing intrinsic cortical dynamics), and quite distinct when patterns were estimated on the basis of separate trials (sharing only the stimulus-driven component). We show that the greater similarity of the representational geometries can be explained by coherent fluctuations of regional-mean activation within visual cortex, reflecting intrinsic dynamics. Using separate trials to study stimulus-driven representations revealed clearer distinctions between the representational geometries: a Gabor wavelet pyramid model explained representational geometry in visual areas V1-3 and a categorical animate-inanimate model in the object-responsive lateral occipital cortex.", "Keywords": ["Functional MRI", "Intrinsic dynamics", "Natural images", "Pattern information", "Representational similarity", "Visual cortex"], "MeSH terms": ["Brain Mapping", "Humans", "Image Processing, Computer-Assisted", "Magnetic Resonance Imaging", "Photic Stimulation", "Visual Cortex", "Visual Perception"], "Authors": [{"First Name": "Linda", "Last Name": "Henriksson", "Affiliation": "MRC Cognition and Brain Sciences Unit, Cambridge CB2 7EF, UK; Brain Research Unit, Department of Neuroscience and Biomedical Engineering, Aalto University, 02150 Espoo, Finland. Electronic address: linda.henriksson@aalto.fi."}, {"First Name": "Seyed-Mahdi", "Last Name": "Khaligh-Razavi", "Affiliation": "MRC Cognition and Brain Sciences Unit, Cambridge CB2 7EF, UK; Computer Science & Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA 02139, USA."}, {"First Name": "Kendrick", "Last Name": "Kay", "Affiliation": "Department of Psychology, Washington University in St. Louis, St. Louis, MO 63130, USA."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "MRC Cognition and Brain Sciences Unit, Cambridge CB2 7EF, UK."}], "Journal": "NeuroImage", "PubDate": "2015Jul01"}, {"PMID": "25774450", "Title": "Retrieval induces adaptive forgetting of competing memories via cortical pattern suppression.", "Abstract": "Remembering a past experience can, surprisingly, cause forgetting. Forgetting arises when other competing traces interfere with retrieval and inhibitory control mechanisms are engaged to suppress the distraction they cause. This form of forgetting is considered to be adaptive because it reduces future interference. The effect of this proposed inhibition process on competing memories has, however, never been observed, as behavioral methods are 'blind' to retrieval dynamics and neuroimaging methods have not isolated retrieval of individual memories. We developed a canonical template tracking method to quantify the activation state of individual target memories and competitors during retrieval. This method revealed that repeatedly retrieving target memories suppressed cortical patterns unique to competitors. Pattern suppression was related to engagement of prefrontal regions that have been implicated in resolving retrieval competition and, critically, predicted later forgetting. Thus, our findings demonstrate a cortical pattern suppression mechanism through which remembering adaptively shapes which aspects of our past remain accessible.", "Keywords": [], "MeSH terms": ["Adaptation, Psychological", "Adult", "Brain Mapping", "Cues", "Female", "Hippocampus", "Humans", "Inhibition, Psychological", "Magnetic Resonance Imaging", "Male", "Memory", "Mental Recall", "Prefrontal Cortex", "Visual Cortex", "Young Adult"], "Authors": [{"First Name": "Maria", "Last Name": "Wimber", "Affiliation": "1] School of Psychology, University of Birmingham, Birmingham, UK. [2] MRC Cognition and Brain Sciences Unit, Cambridge, UK."}, {"First Name": "Arjen", "Last Name": "Alink", "Affiliation": "MRC Cognition and Brain Sciences Unit, Cambridge, UK."}, {"First Name": "Ian", "Last Name": "Charest", "Affiliation": "MRC Cognition and Brain Sciences Unit, Cambridge, UK."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "MRC Cognition and Brain Sciences Unit, Cambridge, UK."}, {"First Name": "Michael C", "Last Name": "Anderson", "Affiliation": "1] MRC Cognition and Brain Sciences Unit, Cambridge, UK. [2] Behavioural and Clinical Neurosciences Institute, Cambridge, UK."}], "Journal": "Nature neuroscience", "PubDate": "2015Apr"}, {"PMID": "25375136", "Title": "Deep supervised, but not unsupervised, models may explain IT cortical representation.", "Abstract": "Inferior temporal (IT) cortex in human and nonhuman primates serves visual object recognition. Computational object-vision models, although continually improving, do not yet reach human performance. It is unclear to what extent the internal representations of computational models can explain the IT representation. Here we investigate a wide range of computational model representations (37 in total), testing their categorization performance and their ability to account for the IT representational geometry. The models include well-known neuroscientific object-recognition models (e.g. HMAX, VisNet) along with several models from computer vision (e.g. SIFT, GIST, self-similarity features, and a deep convolutional neural network). We compared the representational dissimilarity matrices (RDMs) of the model representations with the RDMs obtained from human IT (measured with fMRI) and monkey IT (measured with cell recording) for the same set of stimuli (not used in training the models). Better performing models were more similar to IT in that they showed greater clustering of representational patterns by category. In addition, better performing models also more strongly resembled IT in terms of their within-category representational dissimilarities. Representational geometries were significantly correlated between IT and many of the models. However, the categorical clustering observed in IT was largely unexplained by the unsupervised models. The deep convolutional network, which was trained by supervision with over a million category-labeled images, reached the highest categorization performance and also best explained IT, although it did not fully explain the IT data. Combining the features of this model with appropriate weights and adding linear combinations that maximize the margin between animate and inanimate objects and between faces and other objects yielded a representation that fully explained our IT data. Overall, our results suggest that explaining IT requires computational features trained through supervised learning to emphasize the behaviorally important categorical divisions prominently reflected in IT.", "Keywords": [], "MeSH terms": ["Animals", "Computational Biology", "Haplorhini", "Humans", "Models, Neurological", "Support Vector Machine", "Temporal Lobe"], "Authors": [{"First Name": "Seyed-Mahdi", "Last Name": "Khaligh-Razavi", "Affiliation": "Medical Research Council, Cognition and Brain Sciences Unit, Cambridge, United Kingdom."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Medical Research Council, Cognition and Brain Sciences Unit, Cambridge, United Kingdom."}], "Journal": "PLoS computational biology", "PubDate": "2014Nov"}, {"PMID": "25246586", "Title": "Unique semantic space in the brain of each beholder predicts perceived similarity.", "Abstract": "The unique way in which each of us perceives the world must arise from our brain representations. If brain imaging could reveal an individual's unique mental representation, it could help us understand the biological substrate of our individual experiential worlds in mental health and disease. However, imaging studies of object vision have focused on commonalities between individuals rather than individual differences and on category averages rather than representations of particular objects. Here we investigate the individually unique component of brain representations of particular objects with functional MRI (fMRI). Subjects were presented with unfamiliar and personally meaningful object images while we measured their brain activity on two separate days. We characterized the representational geometry by the dissimilarity matrix of activity patterns elicited by particular object images. The representational geometry remained stable across scanning days and was unique in each individual in early visual cortex and human inferior temporal cortex (hIT). The hIT representation predicted perceived similarity as reflected in dissimilarity judgments. Importantly, hIT predicted the individually unique component of the judgments when the objects were personally meaningful. Our results suggest that hIT brain representational idiosyncrasies accessible to fMRI are expressed in an individual's perceptual judgments. The unique way each of us perceives the world thus might reflect the individually unique representation in high-level visual areas.", "Keywords": ["memory", "neuroimaging", "object representations", "representational similarity analysis", "visual perception"], "MeSH terms": ["Adolescent", "Brain", "Brain Mapping", "Female", "Humans", "Judgment", "Magnetic Resonance Imaging", "Male", "Pattern Recognition, Visual", "Photic Stimulation", "Psychomotor Performance", "Reproducibility of Results", "Semantics", "Visual Pathways", "Young Adult"], "Authors": [{"First Name": "Ian", "Last Name": "Charest", "Affiliation": "Medical Research Council Cognition and Brain Sciences Unit, Cambridge CB2 7EF, United Kingdom; and ian.charest@mrc-cbu.cam.ac.uk nikolaus.kriegeskorte@mrc-cbu.cam.ac.uk."}, {"First Name": "Rogier A", "Last Name": "Kievit", "Affiliation": "Medical Research Council Cognition and Brain Sciences Unit, Cambridge CB2 7EF, United Kingdom; and."}, {"First Name": "Taylor W", "Last Name": "Schmitz", "Affiliation": "Medical Research Council Cognition and Brain Sciences Unit, Cambridge CB2 7EF, United Kingdom; and."}, {"First Name": "Diana", "Last Name": "Deca", "Affiliation": "Institute of Neuroscience, Technische Universit\u00e4t M\u00fcnchen, 80802 Munich, Germany."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Medical Research Council Cognition and Brain Sciences Unit, Cambridge CB2 7EF, United Kingdom; and ian.charest@mrc-cbu.cam.ac.uk nikolaus.kriegeskorte@mrc-cbu.cam.ac.uk."}], "Journal": "Proceedings of the National Academy of Sciences of the United States of America", "PubDate": "2014Oct07"}, {"PMID": "24952643", "Title": "Population coding of affect across stimuli, modalities and individuals.", "Abstract": "It remains unclear how the brain represents external objective sensory events alongside our internal subjective impressions of them--affect. Representational mapping of population activity evoked by complex scenes and basic tastes in humans revealed a neural code supporting a continuous axis of pleasant-to-unpleasant valence. This valence code was distinct from low-level physical and high-level object properties. Although ventral temporal and anterior insular cortices supported valence codes specific to vision and taste, both the medial and lateral orbitofrontal cortices (OFC) maintained a valence code independent of sensory origin. Furthermore, only the OFC code could classify experienced affect across participants. The entire valence spectrum was represented as a collective pattern in regional neural activity as sensory-specific and abstract codes, whereby the subjective quality of affect can be objectively quantified across stimuli, modalities and people.", "Keywords": [], "MeSH terms": ["Adult", "Affect", "Brain Mapping", "Cerebral Cortex", "Female", "Humans", "Individuality", "Magnetic Resonance Imaging", "Male", "Neuroimaging", "Taste Perception", "Visual Perception", "Young Adult"], "Authors": [{"First Name": "Junichi", "Last Name": "Chikazoe", "Affiliation": "Human Neuroscience Institute, Department of Human Development, College of Human Ecology, Cornell University, Ithaca, New York, USA."}, {"First Name": "Daniel H", "Last Name": "Lee", "Affiliation": "Department of Psychology, University of Toronto, Toronto, Ontario, Canada."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Medical Research Council, Cognition and Brain Sciences Unit, Cambridge, UK."}, {"First Name": "Adam K", "Last Name": "Anderson", "Affiliation": "1] Human Neuroscience Institute, Department of Human Development, College of Human Ecology, Cornell University, Ithaca, New York, USA. [2] Department of Psychology, University of Toronto, Toronto, Ontario, Canada."}], "Journal": "Nature neuroscience", "PubDate": "2014Aug"}, {"PMID": "24743308", "Title": "A toolbox for representational similarity analysis.", "Abstract": "Neuronal population codes are increasingly being investigated with multivariate pattern-information analyses. A key challenge is to use measured brain-activity patterns to test computational models of brain information processing. One approach to this problem is representational similarity analysis (RSA), which characterizes a representation in a brain or computational model by the distance matrix of the response patterns elicited by a set of stimuli. The representational distance matrix encapsulates what distinctions between stimuli are emphasized and what distinctions are de-emphasized in the representation. A model is tested by comparing the representational distance matrix it predicts to that of a measured brain region. RSA also enables us to compare representations between stages of processing within a given brain or model, between brain and behavioral data, and between individuals and species. Here, we introduce a Matlab toolbox for RSA. The toolbox supports an analysis approach that is simultaneously data- and hypothesis-driven. It is designed to help integrate a wide range of computational models into the analysis of multichannel brain-activity measurements as provided by modern functional imaging and neuronal recording techniques. Tools for visualization and inference enable the user to relate sets of models to sets of brain regions and to statistically test and compare the models using nonparametric inference methods. The toolbox supports searchlight-based RSA, to continuously map a measured brain volume in search of a neuronal population code with a specific geometry. Finally, we introduce the linear-discriminant t value as a measure of representational discriminability that bridges the gap between linear decoding analyses and RSA. In order to demonstrate the capabilities of the toolbox, we apply it to both simulated and real fMRI data. The key functions are equally applicable to other modalities of brain-activity measurement. The toolbox is freely available to the community under an open-source license agreement (http://www.mrc-cbu.cam.ac.uk/methods-and-resources/toolboxes/license/).", "Keywords": [], "MeSH terms": ["Brain", "Computer Simulation", "Electronic Data Processing", "Humans", "Models, Theoretical"], "Authors": [{"First Name": "Hamed", "Last Name": "Nili", "Affiliation": "MRC Cognition and Brain Sciences Unit, Cambridge, United Kingdom."}, {"First Name": "Cai", "Last Name": "Wingfield", "Affiliation": "Department of Computer Science, University of Bath, Bath, United Kingdom."}, {"First Name": "Alexander", "Last Name": "Walther", "Affiliation": "MRC Cognition and Brain Sciences Unit, Cambridge, United Kingdom."}, {"First Name": "Li", "Last Name": "Su", "Affiliation": "MRC Cognition and Brain Sciences Unit, Cambridge, United Kingdom; Department of Experimental Psychology, University of Cambridge, Cambridge, United Kingdom."}, {"First Name": "William", "Last Name": "Marslen-Wilson", "Affiliation": "Department of Experimental Psychology, University of Cambridge, Cambridge, United Kingdom."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "MRC Cognition and Brain Sciences Unit, Cambridge, United Kingdom."}], "Journal": "PLoS computational biology", "PubDate": "2014Apr"}, {"PMID": "24569825", "Title": "What's there, distinctly, when and where?", "Abstract": "N/A", "Keywords": [], "MeSH terms": ["Animals", "Cerebral Cortex", "Female", "Functional Neuroimaging", "Humans", "Magnetoencephalography", "Male", "Pattern Recognition, Visual"], "Authors": [{"First Name": "Marieke", "Last Name": "Mur", "Affiliation": "Cognition and Brain Sciences Unit, Medical Research Council, Cambridge, UK."}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Cognition and Brain Sciences Unit, Medical Research Council, Cambridge, UK."}], "Journal": "Nature neuroscience", "PubDate": "2014Mar"}, {"PMID": "24324174", "Title": "Awake reactivation predicts memory in humans.", "Abstract": "How are new experiences transformed into memories? Recent findings have shown that activation in brain regions involved in the initial task performance reemerges during postlearning rest, suggesting that \"offline activity\" might be important for this transformation. It is unclear, however, whether such offline activity indeed reflects reactivation of individual learning experiences, whether the amount of event-specific reactivation is directly related to later memory performance, and what brain regions support such event-specific reactivation. Here, we used functional magnetic resonance imaging to assess whether event-specific reactivation occurs spontaneously during an active, postlearning delay period in the human brain. Applying representational similarity analysis, we found that successful recall of individual study events was predicted by the degree of their endogenous reactivation during the delay period. Within the medial temporal lobe, this reactivation was observed in the entorhinal cortex. Beyond the medial temporal lobe, event-specific reactivation was found in the retrosplenial cortex. Controlling for the levels of blood oxygen level-dependent activation and the serial position during encoding, the data suggest that offline reactivation might be a key mechanism for bolstering episodic memory beyond initial study processes. These results open a unique avenue for the systematic investigation of reactivation and consolidation of episodic memories in humans.", "Keywords": [], "MeSH terms": ["Adult", "England", "Female", "Humans", "Magnetic Resonance Imaging", "Male", "Memory", "Memory, Episodic", "Mental Recall", "Models, Neurological", "Oxygen", "Photic Stimulation", "Temporal Lobe"], "Authors": [{"First Name": "Bernhard P", "Last Name": "Staresina", "Affiliation": "Medical Research Council Cognition and Brain Sciences Unit, Cambridge CB2 7EF, United Kingdom."}, {"First Name": "Arjen", "Last Name": "Alink", "Affiliation": "N/A"}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "N/A"}, {"First Name": "Richard N", "Last Name": "Henson", "Affiliation": "N/A"}], "Journal": "Proceedings of the National Academy of Sciences of the United States of America", "PubDate": "2013Dec24"}, {"PMID": "24001004", "Title": "Reaction time for object categorization is predicted by representational distance.", "Abstract": "How does the brain translate an internal representation of an object into a decision about the object's category? Recent studies have uncovered the structure of object representations in inferior temporal cortex (IT) using multivariate pattern analysis methods. These studies have shown that representations of individual object exemplars in IT occupy distinct locations in a high-dimensional activation space, with object exemplar representations clustering into distinguishable regions based on category (e.g., animate vs. inanimate objects). In this study, we hypothesized that a representational boundary between category representations in this activation space also constitutes a decision boundary for categorization. We show that behavioral RTs for categorizing objects are well described by our activation space hypothesis. Interpreted in terms of classical and contemporary models of decision-making, our results suggest that the process of settling on an internal representation of a stimulus is itself partially constitutive of decision-making for object categorization.", "Keywords": [], "MeSH terms": ["Decision Making", "Distance Perception", "Forecasting", "Humans", "Magnetic Resonance Imaging", "Pattern Recognition, Visual", "Photic Stimulation", "Reaction Time", "Temporal Lobe", "Visual Cortex"], "Authors": [{"First Name": "Thomas A", "Last Name": "Carlson", "Affiliation": "Macquarie University, Sydney, Australia."}, {"First Name": "J Brendan", "Last Name": "Ritchie", "Affiliation": "N/A"}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "N/A"}, {"First Name": "Samir", "Last Name": "Durvasula", "Affiliation": "N/A"}, {"First Name": "Junsheng", "Last Name": "Ma", "Affiliation": "N/A"}], "Journal": "Journal of cognitive neuroscience", "PubDate": "2014Jan"}, {"PMID": "23964251", "Title": "fMRI orientation decoding in V1 does not require global maps or globally coherent orientation stimuli.", "Abstract": "The orientation of a large grating can be decoded from V1 functional magnetic resonance imaging (fMRI) data, even at low resolution (3-mm isotropic voxels). This finding has suggested that columnar-level neuronal information might be accessible to fMRI at 3T. However, orientation decodability might alternatively arise from global orientation-preference maps. Such global maps across V1 could result from bottom-up processing, if the preferences of V1 neurons were biased toward particular orientations (e.g., radial from fixation, or cardinal, i.e., vertical or horizontal). Global maps could also arise from local recurrent or top-down processing, reflecting pre-attentive perceptual grouping, attention spreading, or predictive coding of global form. Here we investigate whether fMRI orientation decoding with 2-mm voxels requires (a) globally coherent orientation stimuli and/or (b) global-scale patterns of V1 activity. We used opposite-orientation gratings (balanced about the cardinal orientations) and spirals (balanced about the radial orientation), along with novel patch-swapped variants of these stimuli. The two stimuli of a patch-swapped pair have opposite orientations everywhere (like their globally coherent parent stimuli). However, the two stimuli appear globally similar, a patchwork of opposite orientations. We find that all stimulus pairs are robustly decodable, demonstrating that fMRI orientation decoding does not require globally coherent orientation stimuli. Furthermore, decoding remained robust after spatial high-pass filtering for all stimuli, showing that fine-grained components of the fMRI patterns reflect visual orientations. Consistent with previous studies, we found evidence for global radial and vertical preference maps in V1. However, these were weak or absent for patch-swapped stimuli, suggesting that global preference maps depend on globally coherent orientations and might arise through recurrent or top-down processes related to the perception of global form.", "Keywords": ["decoding", "fMRI", "global form", "hyperacuity", "orientation selectivity", "pattern analysis", "radial bias", "visual cortex"], "MeSH terms": [], "Authors": [{"First Name": "Arjen", "Last Name": "Alink", "Affiliation": "Medical Research Council, Cognition and Brain Sciences Unit Cambridge, UK."}, {"First Name": "Alexandra", "Last Name": "Krugliak", "Affiliation": "N/A"}, {"First Name": "Alexander", "Last Name": "Walther", "Affiliation": "N/A"}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "N/A"}], "Journal": "Frontiers in psychology", "PubDate": "2013"}, {"PMID": "23915056", "Title": "The emergence of semantic meaning in the ventral temporal pathway.", "Abstract": "In the ventral visual pathway, early visual areas encode light patterns on the retina in terms of image properties, for example, edges and color, whereas higher areas encode visual information in terms of objects and categories. At what point does semantic knowledge, as instantiated in human language, emerge? We examined this question by studying whether semantic similarity in language relates to the brain's organization of object representations in inferior temporal cortex (ITC), an area of the brain at the crux of several proposals describing how the brain might represent conceptual knowledge. Semantic relationships among words can be viewed as a geometrical structure with some pairs of words close in their meaning (e.g., man and boy) and other pairs more distant (e.g., man and tomato). ITC's representation of objects similarly can be viewed as a complex structure with some pairs of stimuli evoking similar patterns of activation (e.g., man and boy) and other pairs evoking very different patterns (e.g., man and tomato). In this study, we examined whether the geometry of visual object representations in ITC bears a correspondence to the geometry of semantic relationships between word labels used to describe the objects. We compared ITC's representation to semantic structure, evaluated by explicit ratings of semantic similarity and by five computational measures of semantic similarity. We show that the representational geometry of ITC-but not of earlier visual areas (V1)-is reflected both in explicit behavioral ratings of semantic similarity and also in measures of semantic similarity derived from word usage patterns in natural language. Our findings show that patterns of brain activity in ITC not only reflect the organization of visual information into objects but also represent objects in a format compatible with conceptual thought and language.", "Keywords": [], "MeSH terms": ["Adolescent", "Female", "Humans", "Magnetic Resonance Imaging", "Male", "Photic Stimulation", "Semantics", "Temporal Lobe", "Visual Cortex", "Visual Pathways"], "Authors": [{"First Name": "Thomas A", "Last Name": "Carlson", "Affiliation": "Macquarie University, Sydney, Australia."}, {"First Name": "Ryan A", "Last Name": "Simmons", "Affiliation": "N/A"}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "N/A"}, {"First Name": "L Robert", "Last Name": "Slevc", "Affiliation": "N/A"}], "Journal": "Journal of cognitive neuroscience", "PubDate": "2014Jan"}, {"PMID": "23908380", "Title": "Representational dynamics of object vision: the first 1000 ms.", "Abstract": "Human object recognition is remarkably efficient. In recent years, significant advancements have been made in our understanding of how the brain represents visual objects and organizes them into categories. Recent studies using pattern analyses methods have characterized a representational space of objects in human and primate inferior temporal cortex in which object exemplars are discriminable and cluster according to category (e.g., faces and bodies). In the present study we examined how category structure in object representations emerges in the first 1000 ms of visual processing. In the study, participants viewed 24 object exemplars with a planned categorical structure comprised of four levels ranging from highly specific (individual exemplars) to highly abstract (animate vs. inanimate), while their brain activity was recorded with magnetoencephalography (MEG). We used a sliding time window decoding approach to decode the exemplar and the exemplar's category that participants were viewing on a moment-to-moment basis. We found exemplar and category membership could be decoded from the neuromagnetic recordings shortly after stimulus onset (<100 ms) with peak decodability following thereafter. Latencies for peak decodability varied systematically with the level of category abstraction with more abstract categories emerging later, indicating that the brain hierarchically constructs category representations. In addition, we examined the stationarity of patterns of activity in the brain that encode object category information and show these patterns vary over time, suggesting the brain might use flexible time varying codes to represent visual object categories.", "Keywords": ["brain decoding", "categorization", "magnetoencephalography", "object recognition", "pattern-information analysis"], "MeSH terms": ["Adult", "Brain Mapping", "Cerebral Cortex", "Female", "Humans", "Magnetoencephalography", "Male", "Pattern Recognition, Visual", "Photic Stimulation", "Time Factors", "Vision, Ocular", "Visual Pathways", "Young Adult"], "Authors": [{"First Name": "Thomas", "Last Name": "Carlson", "Affiliation": "Department of Cognitive Sciences, Macquarie University, Sydney, NSW, Australia. thomas.carlson@mq.edu.au"}, {"First Name": "David A", "Last Name": "Tovar", "Affiliation": "N/A"}, {"First Name": "Arjen", "Last Name": "Alink", "Affiliation": "N/A"}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "N/A"}], "Journal": "Journal of vision", "PubDate": "2013Aug01"}, {"PMID": "23876494", "Title": "Representational geometry: integrating cognition, computation, and the brain.", "Abstract": "The cognitive concept of representation plays a key role in theories of brain information processing. However, linking neuronal activity to representational content and cognitive theory remains challenging. Recent studies have characterized the representational geometry of neural population codes by means of representational distance matrices, enabling researchers to compare representations across stages of processing and to test cognitive and computational theories. Representational geometry provides a useful intermediate level of description, capturing both the information represented in a neuronal population code and the format in which it is represented. We review recent insights gained with this approach in perception, memory, cognition, and action. Analyses of representational geometry can compare representations between models and the brain, and promise to explain brain computation as transformation of representational similarity structure.", "Keywords": [], "MeSH terms": ["Brain", "Cognition", "Computer Simulation", "Humans", "Mathematics", "Models, Neurological"], "Authors": [{"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "Medical Research Council, Cognition and Brain Sciences Unit, Cambridge, UK. nikolaus.kriegeskorte@mrc-cbu.cam.ac.uk"}, {"First Name": "Rogier A", "Last Name": "Kievit", "Affiliation": "N/A"}], "Journal": "Trends in cognitive sciences", "PubDate": "2013Aug"}, {"PMID": "23864675", "Title": "Choosing the rules: distinct and overlapping frontoparietal representations of task rules for perceptual decisions.", "Abstract": "Behavior is governed by rules that associate stimuli with responses and outcomes. Human and monkey studies have shown that rule-specific information is widely represented in the frontoparietal cortex. However, it is not known how establishing a rule under different contexts affects its neural representation. Here, we use event-related functional MRI (fMRI) and multivoxel pattern classification methods to investigate the human brain's mechanisms of establishing and maintaining rules for multiple perceptual decision tasks. Rules were either chosen by participants or specifically instructed to them, and the fMRI activation patterns representing rule-specific information were compared between these contexts. We show that frontoparietal regions differ in the properties of their rule representations during active maintenance before execution. First, rule-specific information maintained in the dorsolateral and medial frontal cortex depends on the context in which it was established (chosen vs specified). Second, rule representations maintained in the ventrolateral frontal and parietal cortex are independent of the context in which they were established. Furthermore, we found that the rule-specific coding maintained in anticipation of stimuli may change with execution of the rule: representations in context-independent regions remain invariant from maintenance to execution stages, whereas rule representations in context-dependent regions do not generalize to execution stage. The identification of distinct frontoparietal systems with context-independent and context-dependent task rule representations, and the distinction between anticipatory and executive rule representations, provide new insights into the functional architecture of goal-directed behavior.", "Keywords": [], "MeSH terms": ["Adult", "Brain Mapping", "Decision Making", "Female", "Frontal Lobe", "Humans", "Image Processing, Computer-Assisted", "Learning", "Magnetic Resonance Imaging", "Male", "Parietal Lobe", "Photic Stimulation", "Psychomotor Performance", "Reaction Time", "Visual Perception"], "Authors": [{"First Name": "Jiaxiang", "Last Name": "Zhang", "Affiliation": "Cognition and Brain Sciences Unit, Medical Research Council, Cambridge CB2 7EF, United Kingdom. jiaxiang.zhang@mrc-cbu.cam.ac.uk"}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "N/A"}, {"First Name": "Johan D", "Last Name": "Carlin", "Affiliation": "N/A"}, {"First Name": "James B", "Last Name": "Rowe", "Affiliation": "N/A"}], "Journal": "The Journal of neuroscience : the official journal of the Society for Neuroscience", "PubDate": "2013Jul17"}, {"PMID": "23843508", "Title": "Intrinsic structure of visual exemplar and category representations in macaque brain.", "Abstract": "One of the most remarkable properties of the visual system is the ability to identify and categorize a wide variety of objects effortlessly. However, the underlying neural mechanisms remain elusive. Specifically, the question of how individual object information is represented and intrinsically organized is still poorly understood. To address this question, we presented images of isolated real-world objects spanning a wide range of categories to awake monkeys using a rapid event-related functional magnetic resonance imaging (fMRI) design and analyzed the responses of multiple areas involved in object processing. We found that the multivoxel response patterns to individual exemplars in the inferior temporal (IT) cortex, especially area TE, encoded the animate-inanimate categorical division, with a subordinate cluster of faces within the animate category. In contrast, the individual exemplar representations in V4, the amygdala, and prefrontal cortex showed either no categorical structure, or a categorical structure different from that in IT cortex. Moreover, in the IT face-selective regions (\"face patches\"), especially the anterior face patches, (1) the multivoxel response patterns to individual exemplars showed a categorical distinction between faces and nonface objects (i.e., body parts and inanimate objects), and (2) the regionally averaged activations to individual exemplars showed face-selectivity and within-face exemplar-selectivity. Our findings demonstrate that, at both the single-exemplar and the population level, intrinsic object representation and categorization are organized hierarchically as one moves anteriorly along the ventral pathway, reflecting both modular and distributed processing.", "Keywords": [], "MeSH terms": ["Animals", "Brain", "Brain Mapping", "Macaca mulatta", "Male", "Pattern Recognition, Visual", "Photic Stimulation", "Psychomotor Performance", "Random Allocation", "Visual Cortex"], "Authors": [{"First Name": "Ning", "Last Name": "Liu", "Affiliation": "Section on Neurocircuitry, Laboratory of Brain and Cognition, NIMH/NIH, Bethesda, MD 20892, USA. lning@mail.nih.gov"}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "N/A"}, {"First Name": "Marieke", "Last Name": "Mur", "Affiliation": "N/A"}, {"First Name": "Fadila", "Last Name": "Hadj-Bouziane", "Affiliation": "N/A"}, {"First Name": "Wen-Ming", "Last Name": "Luh", "Affiliation": "N/A"}, {"First Name": "Roger B H", "Last Name": "Tootell", "Affiliation": "N/A"}, {"First Name": "Leslie G", "Last Name": "Ungerleider", "Affiliation": "N/A"}], "Journal": "The Journal of neuroscience : the official journal of the Society for Neuroscience", "PubDate": "2013Jul10"}, {"PMID": "23525516", "Title": "Human Object-Similarity Judgments Reflect and Transcend the Primate-IT Object Representation.", "Abstract": "Primate inferior temporal (IT) cortex is thought to contain a high-level representation of objects at the interface between vision and semantics. This suggests that the perceived similarity of real-world objects might be predicted from the IT representation. Here we show that objects that elicit similar activity patterns in human IT (hIT) tend to be judged as similar by humans. The IT representation explained the human judgments better than early visual cortex, other ventral-stream regions, and a range of computational models. Human similarity judgments exhibited category clusters that reflected several categorical divisions that are prevalent in the IT representation of both human and monkey, including the animate/inanimate and the face/body division. Human judgments also reflected the within-category representation of IT. However, the judgments transcended the IT representation in that they introduced additional categorical divisions. In particular, human judgments emphasized human-related additional divisions between human and non-human animals and between man-made and natural objects. hIT was more similar to monkey IT than to human judgments. One interpretation is that IT has evolved visual-feature detectors that distinguish between animates and inanimates and between faces and bodies because these divisions are fundamental to survival and reproduction for all primate species, and that other brain systems serve to more flexibly introduce species-dependent and evolutionarily more recent divisions.", "Keywords": ["fMRI", "human", "neuronal representation", "object perception", "primate", "representational similarity analysis", "vision"], "MeSH terms": [], "Authors": [{"First Name": "Marieke", "Last Name": "Mur", "Affiliation": "Section on Functional Imaging Methods, Laboratory of Brain and Cognition, National Institute of Mental Health, National Institutes of Health Bethesda, MD, USA ; Department of Cognitive Neuroscience, Faculty of Psychology and Neuroscience, Maastricht University Maastricht, Netherlands."}, {"First Name": "Mirjam", "Last Name": "Meys", "Affiliation": "N/A"}, {"First Name": "Jerzy", "Last Name": "Bodurka", "Affiliation": "N/A"}, {"First Name": "Rainer", "Last Name": "Goebel", "Affiliation": "N/A"}, {"First Name": "Peter A", "Last Name": "Bandettini", "Affiliation": "N/A"}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "N/A"}], "Journal": "Frontiers in psychology", "PubDate": "2013"}, {"PMID": "22802575", "Title": "Abstract encoding of auditory objects in cortical activity patterns.", "Abstract": "The human brain is thought to process auditory objects along a hierarchical temporal \"what\" stream that progressively abstracts object information from the low-level structure (e.g., loudness) as processing proceeds along the middle-to-anterior direction. Empirical demonstrations of abstract object encoding, independent of low-level structure, have relied on speech stimuli, and non-speech studies of object-category encoding (e.g., human vocalizations) often lack a systematic assessment of low-level information (e.g., vocalizations are highly harmonic). It is currently unknown whether abstract encoding constitutes a general functional principle that operates for auditory objects other than speech. We combined multivariate analyses of functional imaging data with an accurate analysis of the low-level acoustical information to examine the abstract encoding of non-speech categories. We observed abstract encoding of the living and human-action sound categories in the fine-grained spatial distribution of activity in the middle-to-posterior temporal cortex (e.g., planum temporale). Abstract encoding of auditory objects appears to extend to non-speech biological sounds and to operate in regions other than the anterior temporal lobe. Neural processes for the abstract encoding of auditory objects might have facilitated the emergence of speech categories in our ancestors.", "Keywords": ["categorization", "condition-rich design", "fMRI", "multivariate information-based mapping", "temporal cortex"], "MeSH terms": ["Acoustic Stimulation", "Adult", "Auditory Perception", "Cerebral Cortex", "Female", "Humans", "Magnetic Resonance Imaging", "Male", "Temporal Lobe", "Young Adult"], "Authors": [{"First Name": "Bruno L", "Last Name": "Giordano", "Affiliation": "Institute of Neuroscience and Psychology, University of Glasgow, Glasgow, UK. brunog@psy.gla.ac.uk"}, {"First Name": "Stephen", "Last Name": "McAdams", "Affiliation": "N/A"}, {"First Name": "Robert J", "Last Name": "Zatorre", "Affiliation": "N/A"}, {"First Name": "Nikolaus", "Last Name": "Kriegeskorte", "Affiliation": "N/A"}, {"First Name": "Pascal", "Last Name": "Belin", "Affiliation": "N/A"}], "Journal": "Cerebral cortex (New York, N.Y. : 1991)", "PubDate": "2013Sep"}]