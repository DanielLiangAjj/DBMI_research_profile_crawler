Animals face complex environments teeming with sensory stimuli. Light, odor, taste, sound, and touch need to be properly encoded in the brain to allow them to understand their natural surrounding and adapt their behavior to survive and thrive. Light in particular is an essential cue for many diurnal animals: it is sensed in the eye by photoreceptors; highly specialized neurons that detect photons. How do neuronal circuits in the brain accurately interpret these photoreceptor signals to extract a variety of features of the visual scene, such as object shape, color, and depth of field? Using the fruit fly model system, we are teasing apart the neuronal circuits underlying two aspects of vision: motion detection and color discrimination. We use a variety of complementary techniques: in vivo single cell patch-clamp recordings, two-photon activity-imaging, optogenetic as well as behavioral paradigms. The long-term goal of the laboratory is to understand how the properties of specific neuronal types and their connectivity within sensory circuits allow for the computations necessary for sensory perception.