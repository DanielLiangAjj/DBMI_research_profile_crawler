Movement is the only way we have of interacting with the world, whether foraging for food or attracting a waiter's attention. Indeed, all communication, including speech, sign language, gestures and writing, is mediated via the motor system. Taking this viewpoint, the purpose of the human brain is to use sensory signals to determine future actions. The goal of our lab is to understand the computational principles underlying human sensorimotor control. We use theoretical studies, computer simulations and human experiments to examine the basis of skilled motor behavior. Our focus is on the control of the hand and arm as a model system that demonstrates many of the features which make sensorimotor control hard. The upper limb has a large number of interacting degrees of freedom and it interacts with many different objects under a variety of environmental conditions. Despite this complexity, healthy humans demonstrate a remarkable ability to generate accurate and appropriate motor behavior when interacting with the world. To examine the computations underlying sensorimotor control, we have developed a research program that uses computational techniques from machine learning, control theory and signal processing together with novel experimental techniques that include robotic interfaces and virtual reality systems that allow for precise experimental control over sensory inputs and task variables. There are five broad areas to our research program: (1) Motor planning and optimal control, (2) Probabilistic models of sensorimotor control, (3) Predictive models for estimation, control & sensory processing, (4) Motor learning of novel dynamics, and (5) The interplay between decision making and sensorimotor control.